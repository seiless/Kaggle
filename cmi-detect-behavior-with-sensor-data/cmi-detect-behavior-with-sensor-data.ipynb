{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c8df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    target = \"gesture\"\n",
    "    folds = 5\n",
    "    seed = 42\n",
    "    folder_path = 'csvfile/'\n",
    "    except_cols = ['row_id']\n",
    "    importance_threshold=1e-4\n",
    "    target_gestures = [\n",
    "        'Above ear - pull hair',\n",
    "        'Cheek - pinch skin',\n",
    "        'Eyebrow - pull hair',\n",
    "        'Eyelash - pull hair',\n",
    "        'Forehead - pull hairline',\n",
    "        'Forehead - scratch',\n",
    "        'Neck - pinch skin',\n",
    "        'Neck - scratch',\n",
    "        ]\n",
    "    non_target_gestures = [\n",
    "        'Write name on leg',\n",
    "        'Wave hello',\n",
    "        'Glasses on/off',\n",
    "        'Text on phone',\n",
    "        'Write name in air',\n",
    "        'Feel around in tray and pull out an object',\n",
    "        'Scratch knee/leg skin',\n",
    "        'Pull air toward your face',\n",
    "        'Drink from bottle/cup',\n",
    "        'Pinch knee/leg skin'\n",
    "        ]\n",
    "    all_gestures = target_gestures + non_target_gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ca2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import cv2\n",
    "import itertools\n",
    "import random\n",
    "from scipy.stats import zscore, skew\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin,TransformerMixin, RegressorMixin,clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, KBinsDiscretizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import norm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import itertools\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6527e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(CFG.folder_path + 'train.csv').join(pl.read_csv(CFG.folder_path + 'train_demographics.csv'), on=\"subject\", how=\"left\")\n",
    "test = pl.read_csv(CFG.folder_path + 'test.csv').join(pl.read_csv(CFG.folder_path + 'test_demographics.csv'), on=\"subject\", how=\"left\")\n",
    "tof_cols_ = [f'tof_{s}_v{p}' for s in range(1, 6) for p in range(64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f180465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contest_metric(y_true, y_pred, target_gestures):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    target_gestures = set(target_gestures)\n",
    "    \n",
    "    all_labels = sorted(list(target_gestures | {'non_target'}))\n",
    "\n",
    "    y_true_binary = np.where(np.isin(y_true, list(target_gestures)), 'target', 'non_target')\n",
    "    y_pred_binary = np.where(np.isin(y_pred, list(target_gestures)), 'target', 'non_target')\n",
    "    \n",
    "    binary_f1 = f1_score(y_true_binary, y_pred_binary, pos_label='target', average='binary')\n",
    "\n",
    "    y_true_macro = np.where(np.isin(y_true, list(target_gestures)), y_true, 'non_target')\n",
    "    y_pred_macro = np.where(np.isin(y_pred, list(target_gestures)), y_pred, 'non_target')\n",
    "\n",
    "    macro_f1 = f1_score(y_true_macro, y_pred_macro, labels=all_labels, average='macro')\n",
    "\n",
    "    final_score = (binary_f1 + macro_f1) / 2\n",
    "\n",
    "    return {\n",
    "        'binary_f1': binary_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'final_score': final_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18513d",
   "metadata": {},
   "source": [
    "# 2. Make Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e569de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Polars 데이터프레임 X에서 self.columns를 선택\n",
    "        selected_X = X.select(self.columns)\n",
    "        return selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f04d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToFDataset(Dataset):\n",
    "    \"\"\"\n",
    "    null 값을 원천적으로 방어하도록 수정된 최종 데이터셋 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, df, tof_cols, labels=None):\n",
    "        # --- [핵심 수정] ---\n",
    "        # Polars -> Numpy로 변환하기 전에, 모든 null 값을 -1.0으로 채웁니다.\n",
    "        self.tof_data = (\n",
    "            df.select(tof_cols)\n",
    "            .fill_null(-1.0)\n",
    "            .to_numpy()\n",
    "            .astype(np.float32)\n",
    "        )\n",
    "        # -------------------\n",
    "        \n",
    "        # 만약 이 단계에서도 NaN이 있다면, 원본 데이터 자체에 Inf 등의 이상값이 있다는 의미입니다.\n",
    "        if np.isnan(self.tof_data).any():\n",
    "            print(\"🚨 CRITICAL: NaN detected in data even after fill_null. Check source for Inf values.\")\n",
    "            # Inf 값을 -1로 대체\n",
    "            self.tof_data = np.nan_to_num(self.tof_data, nan=-1.0, posinf=-1.0, neginf=-1.0)\n",
    "\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tof_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tof_vector = self.tof_data[idx]\n",
    "        tof_image = tof_vector.reshape(5, 8, 8)\n",
    "        \n",
    "        # 이 단계에서는 -1만 존재하므로, 정규화 로직은 그대로 유지합니다.\n",
    "        valid_data_mask = (tof_image != -1.0)\n",
    "        normalized_image = np.where(valid_data_mask, tof_image / 254.0, 0)\n",
    "        final_image = np.where(valid_data_mask, normalized_image, -1.0)\n",
    "        \n",
    "        tof_tensor = torch.tensor(final_image, dtype=torch.float32)\n",
    "\n",
    "        if self.labels is not None:\n",
    "            return tof_tensor, self.labels[idx]\n",
    "        else:\n",
    "            return tof_tensor\n",
    "\n",
    "# CNN 모델 클래스\n",
    "class ToF_CNN_Extractor(nn.Module):\n",
    "    def __init__(self, num_classes, feature_dim=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # Input: (N, 5, 8, 8)\n",
    "            nn.Conv2d(in_channels=5, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Flatten(), # -> (N, 64 * 2 * 2) = (N, 256)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 2 * 2, feature_dim), # <-- 64*2*2 에서 128*2*2 (즉, 512)로 수정\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(feature_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 2 * 2, feature_dim),\n",
    "            nn.LeakyReLU(negative_slope=0.01), # ReLU -> LeakyReLU\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(feature_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# CNNFeatureGenerator 클래스 수정\n",
    "# -----------------------------------------------------\n",
    "class CNNFeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_classes, feature_dim=256, epochs=5, batch_size=64, lr=1e-4, verbose=True):\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_dim = feature_dim\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # ToF_CNN_Extractor 모델은 이전에 수정한 '더 커진' 버전을 사용합니다.\n",
    "        self.model = ToF_CNN_Extractor(self.num_classes, self.feature_dim).to(self.device)\n",
    "        \n",
    "        self.tof_cols_ = [f'tof_{s}_v{p}' for s in range(1, 6) for p in range(64)]\n",
    "        \n",
    "        # --- [핵심 수정 부분] ---\n",
    "        # Flatten 후의 실제 피처 개수인 512에 맞춰 피처 이름을 생성합니다.\n",
    "        self.flattened_dim_ = 64 * 2 * 2  # 512\n",
    "        self.feature_names_out_ = [f'cnn_feat_{i}' for i in range(self.flattened_dim_)]\n",
    "        # ------------------------\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # fit 메서드는 이전과 동일합니다.\n",
    "        if self.verbose:\n",
    "            print(f\"CNN Feature Generator: Starting training on {self.device} for {self.epochs} epochs...\")\n",
    "        # (이하 생략)\n",
    "        \n",
    "        train_dataset = ToFDataset(X, self.tof_cols_, labels=y)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "            for inputs, labels in train_loader:\n",
    "                # labels.to() 호출 시 dtype=torch.long을 추가\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device, dtype=torch.long) \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels) # 이제 정상 작동\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            if self.verbose:\n",
    "                if len(train_loader) > 0:\n",
    "                    avg_loss = total_loss / len(train_loader)\n",
    "                    print(f\"  Epoch {epoch+1}/{self.epochs}, Loss: {avg_loss:.6f}\")\n",
    "                else:\n",
    "                    print(f\"  Epoch {epoch+1}/{self.epochs}, train_loader is empty.\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # transform 메서드는 이전과 동일합니다.\n",
    "        if self.verbose:\n",
    "            print(\"CNN Feature Generator: Extracting features...\")\n",
    "        self.model.eval()\n",
    "        transform_dataset = ToFDataset(X, self.tof_cols_, labels=None)\n",
    "        transform_loader = DataLoader(transform_dataset, batch_size=self.batch_size * 2, shuffle=False)\n",
    "        all_features = []\n",
    "        with torch.no_grad():\n",
    "            for inputs in transform_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                features = self.model.feature_extractor(inputs)\n",
    "                all_features.append(features.cpu().numpy())\n",
    "        cnn_features_np = np.concatenate(all_features, axis=0)\n",
    "        \n",
    "        # 이제 스키마(512)와 데이터(512)의 차원이 일치합니다.\n",
    "        return pl.DataFrame(cnn_features_np, schema=self.get_feature_names_out())\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return self.feature_names_out_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43326768",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0137c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFullStackingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    # __init__ 메소드는 변경 없음 (이전과 동일)\n",
    "    def __init__(self, pipelines, model_defs, meta_model,\n",
    "                 n_splits=CFG.folds, random_state=CFG.seed, verbose=True,\n",
    "                 stratify_feature=None, n_bins=10):\n",
    "        self.pipelines = pipelines\n",
    "        self.model_defs = model_defs\n",
    "        self.meta_model = meta_model\n",
    "        self.n_splits = n_splits\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.stratify_feature = stratify_feature\n",
    "        self.n_bins = n_bins\n",
    "        self.fitted_models_ = []\n",
    "        self.label_encoder_ = LabelEncoder()\n",
    "        self.classes_ = None\n",
    "        self.feature_names_in_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # ... (상단 부분은 이전 Polars 버전과 동일) ...\n",
    "        if not isinstance(X, pl.DataFrame):\n",
    "            raise TypeError(\"Input X must be a Polars DataFrame.\")\n",
    "        if not isinstance(y, pl.Series):\n",
    "            raise TypeError(\"Input y must be a Polars Series.\")\n",
    "\n",
    "        self.feature_names_in_ = X.columns\n",
    "        y_encoded = self.label_encoder_.fit_transform(y.to_numpy())\n",
    "        self.classes_ = self.label_encoder_.classes_\n",
    "\n",
    "        n_samples = X.height\n",
    "        n_classes_out = len(self.classes_) if len(self.classes_) > 2 else 1\n",
    "        total_base_models = len(self.pipelines) * len(self.model_defs)\n",
    "        meta_features = np.zeros((n_samples, total_base_models * n_classes_out))\n",
    "\n",
    "        stratify_values = y_encoded\n",
    "        if self.stratify_feature and self.stratify_feature in X.columns:\n",
    "            binner = KBinsDiscretizer(n_bins=self.n_bins, encode='ordinal', strategy='quantile')\n",
    "            stratify_values = binner.fit_transform(X.select(self.stratify_feature).to_pandas()).astype(int).flatten()\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        base_model_counter = 0\n",
    "        for pi, pipeline_def in enumerate(self.pipelines):\n",
    "            for mi, (model_cls, model_params) in enumerate(self.model_defs):\n",
    "                if self.verbose:\n",
    "                    print(f\"\\nTraining Pipeline {pi+1} + Model {model_cls.__name__}\")\n",
    "\n",
    "                oof_preds = np.zeros((n_samples, n_classes_out))\n",
    "                fold_specific_models = []\n",
    "\n",
    "                for fold, (train_idx, val_idx) in enumerate(kf.split(np.zeros(n_samples), stratify_values)):\n",
    "                    if self.verbose: print(f\"  Fold {fold+1}/{self.n_splits}...\")\n",
    "                    \n",
    "                    X_train, X_val = X.slice(train_idx[0], len(train_idx)), X.slice(val_idx[0], len(val_idx))\n",
    "                    y_train_fold, y_val_fold = y_encoded[train_idx], y_encoded[val_idx]\n",
    "                    \n",
    "                    pipeline = clone(pipeline_def).fit(X_train, y_train_fold)\n",
    "                    \n",
    "                    X_train_trans = pipeline.transform(X_train)\n",
    "                    X_val_trans = pipeline.transform(X_val)\n",
    "\n",
    "                    cat_cols = X_train_trans.select(cs.string() | cs.categorical()).columns\n",
    "                    \n",
    "                    model_params_copy = model_params.copy()\n",
    "                    model_name = model_cls.__name__.lower()\n",
    "                    \n",
    "                    if \"catboost\" in model_name:\n",
    "                        model_params_copy[\"cat_features\"] = cat_cols\n",
    "                    elif \"xgb\" in model_name:\n",
    "                        model_params_copy[\"enable_categorical\"] = True\n",
    "                    \n",
    "                    model = model_cls(**model_params_copy)\n",
    "                    \n",
    "                    # [PANDAS-CONVERSION] 모델 학습 직전에 Pandas로 변환\n",
    "                    X_train_pd = X_train_trans.to_pandas()\n",
    "                    X_val_pd = X_val_trans.to_pandas()\n",
    "\n",
    "                    if \"lgbm\" in model_name:\n",
    "                         # LightGBM은 category 타입을 직접 지원\n",
    "                         X_train_pd[cat_cols] = X_train_pd[cat_cols].astype(\"category\")\n",
    "                         X_val_pd[cat_cols] = X_val_pd[cat_cols].astype(\"category\")\n",
    "                         model.fit(X_train_pd, y_train_fold) \n",
    "                    else:\n",
    "                         model.fit(X_train_pd, y_train_fold)\n",
    "                    \n",
    "                    proba_preds = model.predict_proba(X_val_pd) # 변환된 Pandas 데이터로 예측\n",
    "                    \n",
    "                    if n_classes_out == 1:\n",
    "                        oof_preds[val_idx] = proba_preds[:, 1].reshape(-1, 1)\n",
    "                    else:\n",
    "                        oof_preds[val_idx] = proba_preds\n",
    "                    \n",
    "                    fold_specific_models.append((pipeline, model))\n",
    "                \n",
    "                start_col, end_col = base_model_counter, base_model_counter + n_classes_out\n",
    "                meta_features[:, start_col:end_col] = oof_preds\n",
    "                base_model_counter += n_classes_out\n",
    "                \n",
    "                self.fitted_models_.append(fold_specific_models)\n",
    "\n",
    "        self.meta_model.fit(meta_features, y_encoded)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not isinstance(X, pl.DataFrame):\n",
    "            raise TypeError(\"Input X must be a Polars DataFrame.\")\n",
    "        \n",
    "        n_samples = X.height\n",
    "        n_classes_out = len(self.classes_) if len(self.classes_) > 2 else 1\n",
    "        total_base_models = len(self.fitted_models_)\n",
    "        meta_X_test = np.zeros((n_samples, total_base_models * n_classes_out))\n",
    "        \n",
    "        current_meta_col_idx = 0\n",
    "        for fold_models in self.fitted_models_:\n",
    "            fold_preds = []\n",
    "            for pipeline, model in fold_models:\n",
    "                X_trans = pipeline.transform(X)\n",
    "\n",
    "                # [PANDAS-CONVERSION] 모델 예측 직전에 Pandas로 변환\n",
    "                X_trans_pd = X_trans.to_pandas()\n",
    "                \n",
    "                # LGBM을 위한 범주형 타입 변환\n",
    "                cat_cols = X_trans.select(cs.string() | cs.categorical()).columns\n",
    "                if cat_cols:\n",
    "                    X_trans_pd[cat_cols] = X_trans_pd[cat_cols].astype(\"category\")\n",
    "\n",
    "                fold_preds.append(model.predict_proba(X_trans_pd))\n",
    "\n",
    "            averaged_preds = np.mean(np.array(fold_preds), axis=0)\n",
    "            \n",
    "            start_col, end_col = current_meta_col_idx, current_meta_col_idx + n_classes_out\n",
    "            if n_classes_out == 1:\n",
    "                meta_X_test[:, start_col:end_col] = averaged_preds[:, 1].reshape(-1, 1)\n",
    "            else:\n",
    "                meta_X_test[:, start_col:end_col] = averaged_preds\n",
    "            current_meta_col_idx += n_classes_out\n",
    "            \n",
    "        return self.meta_model.predict_proba(meta_X_test)\n",
    "    \n",
    "    # predict와 score 메소드는 변경 없음\n",
    "    def predict(self, X):\n",
    "        final_proba = self.predict_proba(X)\n",
    "        if len(self.classes_) == 2:\n",
    "            predictions_encoded = (final_proba[:, 1] >= 0.5).astype(int)\n",
    "        else:\n",
    "            predictions_encoded = np.argmax(final_proba, axis=1)\n",
    "        return self.label_encoder_.inverse_transform(predictions_encoded)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        # y가 polars series일 수 있으므로 numpy로 변환\n",
    "        y_true = y.to_numpy() if isinstance(y, pl.Series) else np.array(y)\n",
    "        return calculate_contest_metric(y_true, y_pred, CFG.target_gestures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_column_selector_pipeline(columns):\n",
    "    return Pipeline([\n",
    "        ('column_selector', ColumnSelector(columns))\n",
    "    ])\n",
    "\n",
    "def build_cnn_feature_pipeline(num_classes, \n",
    "                               feature_dim=64, \n",
    "                               epochs=50, \n",
    "                               batch_size=128, \n",
    "                               lr=1e-3, \n",
    "                               verbose=True):\n",
    "    return Pipeline([\n",
    "        ('cnn_features', CNNFeatureGenerator(\n",
    "            num_classes=num_classes, \n",
    "            feature_dim=feature_dim,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            lr=lr,\n",
    "            verbose=verbose\n",
    "        ))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfca777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_full = train.drop(['row_id', CFG.target])\n",
    "train_y_full = train[CFG.target]\n",
    "train_X_full_pd = train_X_full.to_pandas()\n",
    "train_y_full_pd = train_y_full.to_pandas()\n",
    "\n",
    "X_train_pd, X_val_pd, y_train_pd, y_val_pd = train_test_split(\n",
    "    train_X_full_pd, train_y_full_pd,\n",
    "    test_size=0.2,\n",
    "    random_state=CFG.seed,\n",
    "    stratify=train_y_full_pd\n",
    ")\n",
    "X_train_20 = pl.from_pandas(X_train_pd)\n",
    "X_val_20 = pl.from_pandas(X_val_pd)\n",
    "y_train_20 = pl.from_pandas(y_train_pd)\n",
    "y_val_20 = pl.from_pandas(y_val_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d691d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = build_column_selector_pipeline(columns=tof_cols_)\n",
    "pipeline2 = build_cnn_feature_pipeline(num_classes=len(CFG.all_gestures))\n",
    "pipelines = [pipeline1,pipeline2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297b34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_defs = [\n",
    "    (CatBoostClassifier, {\n",
    "        'iterations': 2000,\n",
    "        'learning_rate': 0.05,\n",
    "        'depth': 8,\n",
    "        'loss_function': 'MultiClass',\n",
    "        'l2_leaf_reg': 3,\n",
    "        'random_seed': CFG.seed,\n",
    "        'eval_metric': 'MultiClass',\n",
    "        'early_stopping_rounds': 200,\n",
    "        'verbose': 0,\n",
    "        'task_type': 'GPU',\n",
    "        'bootstrap_type': 'Poisson',\n",
    "        'grow_policy': 'Depthwise',\n",
    "        'subsample': 0.8\n",
    "    }),\n",
    "    (XGBClassifier, {\n",
    "        'max_depth': 8,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'subsample': 0.9,\n",
    "        'n_estimators': 2000,\n",
    "        'learning_rate': 0.05,\n",
    "        'gamma': 0.01,\n",
    "        'reg_alpha': 2.0,\n",
    "        'reg_lambda': 1.5,\n",
    "        'max_delta_step': 2,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'random_state': CFG.seed,\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "    }),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ad340b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 피처 생성기 학습...\n",
      "CNN Feature Generator: Starting training on cuda for 10 epochs...\n",
      "  Epoch 1/10, Loss: 2.353439\n",
      "  Epoch 2/10, Loss: 2.138539\n",
      "  Epoch 3/10, Loss: 2.056614\n",
      "  Epoch 4/10, Loss: 2.004709\n",
      "  Epoch 5/10, Loss: 1.968892\n",
      "  Epoch 6/10, Loss: 1.940922\n",
      "  Epoch 7/10, Loss: 1.918660\n",
      "  Epoch 8/10, Loss: 1.899386\n",
      "  Epoch 9/10, Loss: 1.883201\n",
      "  Epoch 10/10, Loss: 1.869609\n",
      "학습 및 검증 데이터에서 피처 추출 중...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "XGBoost 모델 학습 중...\n",
      "예측 및 평가 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namwonjin\\Documents\\Kaggle\\venv\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:55:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 4 최종 점수: 0.8193\n",
      "(Binary F1: 0.8967, Macro F1: 0.7420)\n"
     ]
    }
   ],
   "source": [
    "# 1. 레이블 인코딩 (이미 이전 단계에서 수행했다면 생략 가능)\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train_20)\n",
    "y_val_encoded = le.transform(y_val_20)\n",
    "\n",
    "# 2. 파이프라인 및 모델 정의\n",
    "# CNNFeatureGenerator는 재사용하거나 새로 생성할 수 있습니다. 여기서는 새로 생성합니다.\n",
    "cnn_pipeline_xgb = CNNFeatureGenerator(\n",
    "    num_classes=len(CFG.all_gestures),\n",
    "    feature_dim=64,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    lr=1e-4,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "xgb_model_cnn = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=CFG.seed,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    ")\n",
    "\n",
    "# 3. CNN 피처 생성 및 변환\n",
    "print(\"CNN 피처 생성기 학습...\")\n",
    "cnn_pipeline_xgb.fit(X_train_20, y_train_encoded)\n",
    "\n",
    "print(\"학습 및 검증 데이터에서 피처 추출 중...\")\n",
    "X_train_cnn_xgb = cnn_pipeline_xgb.transform(X_train_20)\n",
    "X_val_cnn_xgb = cnn_pipeline_xgb.transform(X_val_20)\n",
    "\n",
    "# 4. XGBoost 모델 학습\n",
    "print(\"XGBoost 모델 학습 중...\")\n",
    "xgb_model_cnn.fit(X_train_cnn_xgb.to_pandas(), y_train_encoded)\n",
    "\n",
    "# 5. 예측 및 평가\n",
    "print(\"예측 및 평가 중...\")\n",
    "y_pred_encoded = xgb_model_cnn.predict(X_val_cnn_xgb.to_pandas())\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "score = calculate_contest_metric(y_val_20.to_numpy(), y_pred, CFG.target_gestures)\n",
    "\n",
    "print(f\"테스트 4 최종 점수: {score['final_score']:.4f}\")\n",
    "print(f\"(Binary F1: {score['binary_f1']:.4f}, Macro F1: {score['macro_f1']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8fb526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Pipeline 1 + Model CatBoostClassifier\n",
      "  Fold 1/5...\n",
      "  Fold 2/5...\n",
      "  Fold 3/5...\n",
      "  Fold 4/5...\n",
      "  Fold 5/5...\n",
      "\n",
      "Training Pipeline 1 + Model XGBClassifier\n",
      "  Fold 1/5...\n",
      "  Fold 2/5...\n",
      "  Fold 3/5...\n",
      "  Fold 4/5...\n",
      "  Fold 5/5...\n",
      "\n",
      "Training Pipeline 2 + Model CatBoostClassifier\n",
      "  Fold 1/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.784440\n",
      "  Epoch 2/50, Loss: 2.751245\n",
      "  Epoch 3/50, Loss: 2.736000\n",
      "  Epoch 4/50, Loss: 2.721005\n",
      "  Epoch 5/50, Loss: 2.707359\n",
      "  Epoch 6/50, Loss: 2.694403\n",
      "  Epoch 7/50, Loss: 2.682366\n",
      "  Epoch 8/50, Loss: 2.671793\n",
      "  Epoch 9/50, Loss: 2.661504\n",
      "  Epoch 10/50, Loss: 2.652891\n",
      "  Epoch 11/50, Loss: 2.644945\n",
      "  Epoch 12/50, Loss: 2.636849\n",
      "  Epoch 13/50, Loss: 2.630491\n",
      "  Epoch 14/50, Loss: 2.624812\n",
      "  Epoch 15/50, Loss: 2.617692\n",
      "  Epoch 16/50, Loss: 2.612284\n",
      "  Epoch 17/50, Loss: 2.607305\n",
      "  Epoch 18/50, Loss: 2.602419\n",
      "  Epoch 19/50, Loss: 2.597887\n",
      "  Epoch 20/50, Loss: 2.593732\n",
      "  Epoch 21/50, Loss: 2.590371\n",
      "  Epoch 22/50, Loss: 2.586096\n",
      "  Epoch 23/50, Loss: 2.582743\n",
      "  Epoch 24/50, Loss: 2.580290\n",
      "  Epoch 25/50, Loss: 2.576913\n",
      "  Epoch 26/50, Loss: 2.574104\n",
      "  Epoch 27/50, Loss: 2.570368\n",
      "  Epoch 28/50, Loss: 2.568428\n",
      "  Epoch 29/50, Loss: 2.567077\n",
      "  Epoch 30/50, Loss: 2.563439\n",
      "  Epoch 31/50, Loss: 2.561718\n",
      "  Epoch 32/50, Loss: 2.559836\n",
      "  Epoch 33/50, Loss: 2.556986\n",
      "  Epoch 34/50, Loss: 2.554043\n",
      "  Epoch 35/50, Loss: 2.553088\n",
      "  Epoch 36/50, Loss: 2.551787\n",
      "  Epoch 37/50, Loss: 2.550968\n",
      "  Epoch 38/50, Loss: 2.548749\n",
      "  Epoch 39/50, Loss: 2.546555\n",
      "  Epoch 40/50, Loss: 2.545296\n",
      "  Epoch 41/50, Loss: 2.543905\n",
      "  Epoch 42/50, Loss: 2.542755\n",
      "  Epoch 43/50, Loss: 2.540513\n",
      "  Epoch 44/50, Loss: 2.539632\n",
      "  Epoch 45/50, Loss: 2.538804\n",
      "  Epoch 46/50, Loss: 2.537113\n",
      "  Epoch 47/50, Loss: 2.535698\n",
      "  Epoch 48/50, Loss: 2.535891\n",
      "  Epoch 49/50, Loss: 2.533731\n",
      "  Epoch 50/50, Loss: 2.532574\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 2/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.786142\n",
      "  Epoch 2/50, Loss: 2.753119\n",
      "  Epoch 3/50, Loss: 2.737663\n",
      "  Epoch 4/50, Loss: 2.723820\n",
      "  Epoch 5/50, Loss: 2.710859\n",
      "  Epoch 6/50, Loss: 2.698376\n",
      "  Epoch 7/50, Loss: 2.686079\n",
      "  Epoch 8/50, Loss: 2.676078\n",
      "  Epoch 9/50, Loss: 2.667047\n",
      "  Epoch 10/50, Loss: 2.657396\n",
      "  Epoch 11/50, Loss: 2.648990\n",
      "  Epoch 12/50, Loss: 2.641629\n",
      "  Epoch 13/50, Loss: 2.634344\n",
      "  Epoch 14/50, Loss: 2.627215\n",
      "  Epoch 15/50, Loss: 2.623078\n",
      "  Epoch 16/50, Loss: 2.616620\n",
      "  Epoch 17/50, Loss: 2.610494\n",
      "  Epoch 18/50, Loss: 2.607054\n",
      "  Epoch 19/50, Loss: 2.602564\n",
      "  Epoch 20/50, Loss: 2.597404\n",
      "  Epoch 21/50, Loss: 2.594220\n",
      "  Epoch 22/50, Loss: 2.590053\n",
      "  Epoch 23/50, Loss: 2.587401\n",
      "  Epoch 24/50, Loss: 2.583282\n",
      "  Epoch 25/50, Loss: 2.580181\n",
      "  Epoch 26/50, Loss: 2.576961\n",
      "  Epoch 27/50, Loss: 2.573712\n",
      "  Epoch 28/50, Loss: 2.572476\n",
      "  Epoch 29/50, Loss: 2.568617\n",
      "  Epoch 30/50, Loss: 2.566381\n",
      "  Epoch 31/50, Loss: 2.564202\n",
      "  Epoch 32/50, Loss: 2.562096\n",
      "  Epoch 33/50, Loss: 2.559896\n",
      "  Epoch 34/50, Loss: 2.558639\n",
      "  Epoch 35/50, Loss: 2.556129\n",
      "  Epoch 36/50, Loss: 2.554672\n",
      "  Epoch 37/50, Loss: 2.552446\n",
      "  Epoch 38/50, Loss: 2.550160\n",
      "  Epoch 39/50, Loss: 2.548817\n",
      "  Epoch 40/50, Loss: 2.547096\n",
      "  Epoch 41/50, Loss: 2.546216\n",
      "  Epoch 42/50, Loss: 2.544449\n",
      "  Epoch 43/50, Loss: 2.542381\n",
      "  Epoch 44/50, Loss: 2.540728\n",
      "  Epoch 45/50, Loss: 2.540219\n",
      "  Epoch 46/50, Loss: 2.538448\n",
      "  Epoch 47/50, Loss: 2.537721\n",
      "  Epoch 48/50, Loss: 2.535401\n",
      "  Epoch 49/50, Loss: 2.535216\n",
      "  Epoch 50/50, Loss: 2.534107\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 3/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.784078\n",
      "  Epoch 2/50, Loss: 2.753983\n",
      "  Epoch 3/50, Loss: 2.738161\n",
      "  Epoch 4/50, Loss: 2.723739\n",
      "  Epoch 5/50, Loss: 2.709938\n",
      "  Epoch 6/50, Loss: 2.697438\n",
      "  Epoch 7/50, Loss: 2.684469\n",
      "  Epoch 8/50, Loss: 2.674650\n",
      "  Epoch 9/50, Loss: 2.664122\n",
      "  Epoch 10/50, Loss: 2.655800\n",
      "  Epoch 11/50, Loss: 2.646977\n",
      "  Epoch 12/50, Loss: 2.639399\n",
      "  Epoch 13/50, Loss: 2.631451\n",
      "  Epoch 14/50, Loss: 2.625718\n",
      "  Epoch 15/50, Loss: 2.620377\n",
      "  Epoch 16/50, Loss: 2.613528\n",
      "  Epoch 17/50, Loss: 2.608159\n",
      "  Epoch 18/50, Loss: 2.603764\n",
      "  Epoch 19/50, Loss: 2.599051\n",
      "  Epoch 20/50, Loss: 2.593903\n",
      "  Epoch 21/50, Loss: 2.591625\n",
      "  Epoch 22/50, Loss: 2.586668\n",
      "  Epoch 23/50, Loss: 2.583995\n",
      "  Epoch 24/50, Loss: 2.580257\n",
      "  Epoch 25/50, Loss: 2.577259\n",
      "  Epoch 26/50, Loss: 2.575150\n",
      "  Epoch 27/50, Loss: 2.571395\n",
      "  Epoch 28/50, Loss: 2.568651\n",
      "  Epoch 29/50, Loss: 2.567423\n",
      "  Epoch 30/50, Loss: 2.564719\n",
      "  Epoch 31/50, Loss: 2.561618\n",
      "  Epoch 32/50, Loss: 2.559159\n",
      "  Epoch 33/50, Loss: 2.557440\n",
      "  Epoch 34/50, Loss: 2.555683\n",
      "  Epoch 35/50, Loss: 2.553306\n",
      "  Epoch 36/50, Loss: 2.552773\n",
      "  Epoch 37/50, Loss: 2.550431\n",
      "  Epoch 38/50, Loss: 2.548860\n",
      "  Epoch 39/50, Loss: 2.547006\n",
      "  Epoch 40/50, Loss: 2.544912\n",
      "  Epoch 41/50, Loss: 2.544051\n",
      "  Epoch 42/50, Loss: 2.542156\n",
      "  Epoch 43/50, Loss: 2.541038\n",
      "  Epoch 44/50, Loss: 2.539310\n",
      "  Epoch 45/50, Loss: 2.538306\n",
      "  Epoch 46/50, Loss: 2.537838\n",
      "  Epoch 47/50, Loss: 2.536083\n",
      "  Epoch 48/50, Loss: 2.535519\n",
      "  Epoch 49/50, Loss: 2.532977\n",
      "  Epoch 50/50, Loss: 2.532768\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 4/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.781847\n",
      "  Epoch 2/50, Loss: 2.750618\n",
      "  Epoch 3/50, Loss: 2.734823\n",
      "  Epoch 4/50, Loss: 2.720772\n",
      "  Epoch 5/50, Loss: 2.707485\n",
      "  Epoch 6/50, Loss: 2.695265\n",
      "  Epoch 7/50, Loss: 2.683891\n",
      "  Epoch 8/50, Loss: 2.672582\n",
      "  Epoch 9/50, Loss: 2.663323\n",
      "  Epoch 10/50, Loss: 2.654578\n",
      "  Epoch 11/50, Loss: 2.646242\n",
      "  Epoch 12/50, Loss: 2.639369\n",
      "  Epoch 13/50, Loss: 2.631545\n",
      "  Epoch 14/50, Loss: 2.625575\n",
      "  Epoch 15/50, Loss: 2.620853\n",
      "  Epoch 16/50, Loss: 2.614394\n",
      "  Epoch 17/50, Loss: 2.610402\n",
      "  Epoch 18/50, Loss: 2.605590\n",
      "  Epoch 19/50, Loss: 2.601772\n",
      "  Epoch 20/50, Loss: 2.596839\n",
      "  Epoch 21/50, Loss: 2.593173\n",
      "  Epoch 22/50, Loss: 2.589876\n",
      "  Epoch 23/50, Loss: 2.586862\n",
      "  Epoch 24/50, Loss: 2.582002\n",
      "  Epoch 25/50, Loss: 2.579542\n",
      "  Epoch 26/50, Loss: 2.576469\n",
      "  Epoch 27/50, Loss: 2.574024\n",
      "  Epoch 28/50, Loss: 2.571350\n",
      "  Epoch 29/50, Loss: 2.568766\n",
      "  Epoch 30/50, Loss: 2.567035\n",
      "  Epoch 31/50, Loss: 2.563252\n",
      "  Epoch 32/50, Loss: 2.563770\n",
      "  Epoch 33/50, Loss: 2.561554\n",
      "  Epoch 34/50, Loss: 2.559478\n",
      "  Epoch 35/50, Loss: 2.556719\n",
      "  Epoch 36/50, Loss: 2.555793\n",
      "  Epoch 37/50, Loss: 2.553582\n",
      "  Epoch 38/50, Loss: 2.551516\n",
      "  Epoch 39/50, Loss: 2.550423\n",
      "  Epoch 40/50, Loss: 2.549596\n",
      "  Epoch 41/50, Loss: 2.547410\n",
      "  Epoch 42/50, Loss: 2.546681\n",
      "  Epoch 43/50, Loss: 2.545050\n",
      "  Epoch 44/50, Loss: 2.542885\n",
      "  Epoch 45/50, Loss: 2.540811\n",
      "  Epoch 46/50, Loss: 2.540926\n",
      "  Epoch 47/50, Loss: 2.540170\n",
      "  Epoch 48/50, Loss: 2.537997\n",
      "  Epoch 49/50, Loss: 2.537087\n",
      "  Epoch 50/50, Loss: 2.536327\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 5/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.780800\n",
      "  Epoch 2/50, Loss: 2.751819\n",
      "  Epoch 3/50, Loss: 2.737492\n",
      "  Epoch 4/50, Loss: 2.723290\n",
      "  Epoch 5/50, Loss: 2.709673\n",
      "  Epoch 6/50, Loss: 2.696761\n",
      "  Epoch 7/50, Loss: 2.685608\n",
      "  Epoch 8/50, Loss: 2.674672\n",
      "  Epoch 9/50, Loss: 2.665408\n",
      "  Epoch 10/50, Loss: 2.656045\n",
      "  Epoch 11/50, Loss: 2.647486\n",
      "  Epoch 12/50, Loss: 2.640202\n",
      "  Epoch 13/50, Loss: 2.633530\n",
      "  Epoch 14/50, Loss: 2.627289\n",
      "  Epoch 15/50, Loss: 2.621527\n",
      "  Epoch 16/50, Loss: 2.615698\n",
      "  Epoch 17/50, Loss: 2.610704\n",
      "  Epoch 18/50, Loss: 2.606300\n",
      "  Epoch 19/50, Loss: 2.600663\n",
      "  Epoch 20/50, Loss: 2.596765\n",
      "  Epoch 21/50, Loss: 2.592313\n",
      "  Epoch 22/50, Loss: 2.589569\n",
      "  Epoch 23/50, Loss: 2.585758\n",
      "  Epoch 24/50, Loss: 2.583618\n",
      "  Epoch 25/50, Loss: 2.579265\n",
      "  Epoch 26/50, Loss: 2.577310\n",
      "  Epoch 27/50, Loss: 2.573559\n",
      "  Epoch 28/50, Loss: 2.571643\n",
      "  Epoch 29/50, Loss: 2.568550\n",
      "  Epoch 30/50, Loss: 2.566380\n",
      "  Epoch 31/50, Loss: 2.564247\n",
      "  Epoch 32/50, Loss: 2.562969\n",
      "  Epoch 33/50, Loss: 2.559456\n",
      "  Epoch 34/50, Loss: 2.558289\n",
      "  Epoch 35/50, Loss: 2.557516\n",
      "  Epoch 36/50, Loss: 2.553396\n",
      "  Epoch 37/50, Loss: 2.552629\n",
      "  Epoch 38/50, Loss: 2.551341\n",
      "  Epoch 39/50, Loss: 2.549967\n",
      "  Epoch 40/50, Loss: 2.549204\n",
      "  Epoch 41/50, Loss: 2.547204\n",
      "  Epoch 42/50, Loss: 2.546362\n",
      "  Epoch 43/50, Loss: 2.544970\n",
      "  Epoch 44/50, Loss: 2.542019\n",
      "  Epoch 45/50, Loss: 2.540681\n",
      "  Epoch 46/50, Loss: 2.540508\n",
      "  Epoch 47/50, Loss: 2.539143\n",
      "  Epoch 48/50, Loss: 2.538091\n",
      "  Epoch 49/50, Loss: 2.536053\n",
      "  Epoch 50/50, Loss: 2.534703\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "\n",
      "Training Pipeline 2 + Model XGBClassifier\n",
      "  Fold 1/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.783812\n",
      "  Epoch 2/50, Loss: 2.754338\n",
      "  Epoch 3/50, Loss: 2.739351\n",
      "  Epoch 4/50, Loss: 2.725722\n",
      "  Epoch 5/50, Loss: 2.712831\n",
      "  Epoch 6/50, Loss: 2.700917\n",
      "  Epoch 7/50, Loss: 2.690186\n",
      "  Epoch 8/50, Loss: 2.679615\n",
      "  Epoch 9/50, Loss: 2.669700\n",
      "  Epoch 10/50, Loss: 2.660024\n",
      "  Epoch 11/50, Loss: 2.651222\n",
      "  Epoch 12/50, Loss: 2.644004\n",
      "  Epoch 13/50, Loss: 2.636311\n",
      "  Epoch 14/50, Loss: 2.629707\n",
      "  Epoch 15/50, Loss: 2.623058\n",
      "  Epoch 16/50, Loss: 2.617601\n",
      "  Epoch 17/50, Loss: 2.611911\n",
      "  Epoch 18/50, Loss: 2.607169\n",
      "  Epoch 19/50, Loss: 2.602721\n",
      "  Epoch 20/50, Loss: 2.599653\n",
      "  Epoch 21/50, Loss: 2.593712\n",
      "  Epoch 22/50, Loss: 2.591905\n",
      "  Epoch 23/50, Loss: 2.587622\n",
      "  Epoch 24/50, Loss: 2.584571\n",
      "  Epoch 25/50, Loss: 2.581610\n",
      "  Epoch 26/50, Loss: 2.578861\n",
      "  Epoch 27/50, Loss: 2.575449\n",
      "  Epoch 28/50, Loss: 2.573669\n",
      "  Epoch 29/50, Loss: 2.571155\n",
      "  Epoch 30/50, Loss: 2.567614\n",
      "  Epoch 31/50, Loss: 2.566021\n",
      "  Epoch 32/50, Loss: 2.563422\n",
      "  Epoch 33/50, Loss: 2.561333\n",
      "  Epoch 34/50, Loss: 2.559553\n",
      "  Epoch 35/50, Loss: 2.559001\n",
      "  Epoch 36/50, Loss: 2.555544\n",
      "  Epoch 37/50, Loss: 2.553366\n",
      "  Epoch 38/50, Loss: 2.552634\n",
      "  Epoch 39/50, Loss: 2.549904\n",
      "  Epoch 40/50, Loss: 2.548555\n",
      "  Epoch 41/50, Loss: 2.547761\n",
      "  Epoch 42/50, Loss: 2.546905\n",
      "  Epoch 43/50, Loss: 2.545952\n",
      "  Epoch 44/50, Loss: 2.543256\n",
      "  Epoch 45/50, Loss: 2.542643\n",
      "  Epoch 46/50, Loss: 2.540054\n",
      "  Epoch 47/50, Loss: 2.538246\n",
      "  Epoch 48/50, Loss: 2.537461\n",
      "  Epoch 49/50, Loss: 2.537156\n",
      "  Epoch 50/50, Loss: 2.535711\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 2/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.785009\n",
      "  Epoch 2/50, Loss: 2.753158\n",
      "  Epoch 3/50, Loss: 2.738837\n",
      "  Epoch 4/50, Loss: 2.725610\n",
      "  Epoch 5/50, Loss: 2.712146\n",
      "  Epoch 6/50, Loss: 2.700838\n",
      "  Epoch 7/50, Loss: 2.688954\n",
      "  Epoch 8/50, Loss: 2.678653\n",
      "  Epoch 9/50, Loss: 2.668694\n",
      "  Epoch 10/50, Loss: 2.660242\n",
      "  Epoch 11/50, Loss: 2.652679\n",
      "  Epoch 12/50, Loss: 2.644616\n",
      "  Epoch 13/50, Loss: 2.637071\n",
      "  Epoch 14/50, Loss: 2.632235\n",
      "  Epoch 15/50, Loss: 2.625934\n",
      "  Epoch 16/50, Loss: 2.620614\n",
      "  Epoch 17/50, Loss: 2.615616\n",
      "  Epoch 18/50, Loss: 2.611099\n",
      "  Epoch 19/50, Loss: 2.605669\n",
      "  Epoch 20/50, Loss: 2.601961\n",
      "  Epoch 21/50, Loss: 2.598574\n",
      "  Epoch 22/50, Loss: 2.594981\n",
      "  Epoch 23/50, Loss: 2.590837\n",
      "  Epoch 24/50, Loss: 2.588124\n",
      "  Epoch 25/50, Loss: 2.585160\n",
      "  Epoch 26/50, Loss: 2.582197\n",
      "  Epoch 27/50, Loss: 2.579047\n",
      "  Epoch 28/50, Loss: 2.576317\n",
      "  Epoch 29/50, Loss: 2.574841\n",
      "  Epoch 30/50, Loss: 2.571843\n",
      "  Epoch 31/50, Loss: 2.569167\n",
      "  Epoch 32/50, Loss: 2.567038\n",
      "  Epoch 33/50, Loss: 2.565075\n",
      "  Epoch 34/50, Loss: 2.562913\n",
      "  Epoch 35/50, Loss: 2.561313\n",
      "  Epoch 36/50, Loss: 2.558925\n",
      "  Epoch 37/50, Loss: 2.557627\n",
      "  Epoch 38/50, Loss: 2.554753\n",
      "  Epoch 39/50, Loss: 2.554422\n",
      "  Epoch 40/50, Loss: 2.551171\n",
      "  Epoch 41/50, Loss: 2.551162\n",
      "  Epoch 42/50, Loss: 2.549033\n",
      "  Epoch 43/50, Loss: 2.547287\n",
      "  Epoch 44/50, Loss: 2.546771\n",
      "  Epoch 45/50, Loss: 2.544981\n",
      "  Epoch 46/50, Loss: 2.542430\n",
      "  Epoch 47/50, Loss: 2.541577\n",
      "  Epoch 48/50, Loss: 2.540766\n",
      "  Epoch 49/50, Loss: 2.539338\n",
      "  Epoch 50/50, Loss: 2.538220\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 3/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.781145\n",
      "  Epoch 2/50, Loss: 2.751268\n",
      "  Epoch 3/50, Loss: 2.735836\n",
      "  Epoch 4/50, Loss: 2.720971\n",
      "  Epoch 5/50, Loss: 2.707340\n",
      "  Epoch 6/50, Loss: 2.695097\n",
      "  Epoch 7/50, Loss: 2.683162\n",
      "  Epoch 8/50, Loss: 2.672370\n",
      "  Epoch 9/50, Loss: 2.662332\n",
      "  Epoch 10/50, Loss: 2.653266\n",
      "  Epoch 11/50, Loss: 2.644985\n",
      "  Epoch 12/50, Loss: 2.637470\n",
      "  Epoch 13/50, Loss: 2.630692\n",
      "  Epoch 14/50, Loss: 2.624185\n",
      "  Epoch 15/50, Loss: 2.618555\n",
      "  Epoch 16/50, Loss: 2.612782\n",
      "  Epoch 17/50, Loss: 2.608276\n",
      "  Epoch 18/50, Loss: 2.603724\n",
      "  Epoch 19/50, Loss: 2.596638\n",
      "  Epoch 20/50, Loss: 2.594256\n",
      "  Epoch 21/50, Loss: 2.589796\n",
      "  Epoch 22/50, Loss: 2.586596\n",
      "  Epoch 23/50, Loss: 2.583516\n",
      "  Epoch 24/50, Loss: 2.579947\n",
      "  Epoch 25/50, Loss: 2.576843\n",
      "  Epoch 26/50, Loss: 2.575702\n",
      "  Epoch 27/50, Loss: 2.571443\n",
      "  Epoch 28/50, Loss: 2.568537\n",
      "  Epoch 29/50, Loss: 2.567138\n",
      "  Epoch 30/50, Loss: 2.564581\n",
      "  Epoch 31/50, Loss: 2.561596\n",
      "  Epoch 32/50, Loss: 2.559535\n",
      "  Epoch 33/50, Loss: 2.557395\n",
      "  Epoch 34/50, Loss: 2.556361\n",
      "  Epoch 35/50, Loss: 2.553056\n",
      "  Epoch 36/50, Loss: 2.551551\n",
      "  Epoch 37/50, Loss: 2.549735\n",
      "  Epoch 38/50, Loss: 2.547797\n",
      "  Epoch 39/50, Loss: 2.546681\n",
      "  Epoch 40/50, Loss: 2.545820\n",
      "  Epoch 41/50, Loss: 2.543278\n",
      "  Epoch 42/50, Loss: 2.542103\n",
      "  Epoch 43/50, Loss: 2.540289\n",
      "  Epoch 44/50, Loss: 2.539608\n",
      "  Epoch 45/50, Loss: 2.537849\n",
      "  Epoch 46/50, Loss: 2.535088\n",
      "  Epoch 47/50, Loss: 2.534922\n",
      "  Epoch 48/50, Loss: 2.534386\n",
      "  Epoch 49/50, Loss: 2.533473\n",
      "  Epoch 50/50, Loss: 2.532480\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 4/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.780348\n",
      "  Epoch 2/50, Loss: 2.750330\n",
      "  Epoch 3/50, Loss: 2.734869\n",
      "  Epoch 4/50, Loss: 2.720709\n",
      "  Epoch 5/50, Loss: 2.707793\n",
      "  Epoch 6/50, Loss: 2.694621\n",
      "  Epoch 7/50, Loss: 2.682975\n",
      "  Epoch 8/50, Loss: 2.672849\n",
      "  Epoch 9/50, Loss: 2.662792\n",
      "  Epoch 10/50, Loss: 2.654099\n",
      "  Epoch 11/50, Loss: 2.644826\n",
      "  Epoch 12/50, Loss: 2.637952\n",
      "  Epoch 13/50, Loss: 2.630921\n",
      "  Epoch 14/50, Loss: 2.624104\n",
      "  Epoch 15/50, Loss: 2.617828\n",
      "  Epoch 16/50, Loss: 2.612315\n",
      "  Epoch 17/50, Loss: 2.607600\n",
      "  Epoch 18/50, Loss: 2.601784\n",
      "  Epoch 19/50, Loss: 2.597989\n",
      "  Epoch 20/50, Loss: 2.593542\n",
      "  Epoch 21/50, Loss: 2.588958\n",
      "  Epoch 22/50, Loss: 2.586896\n",
      "  Epoch 23/50, Loss: 2.581743\n",
      "  Epoch 24/50, Loss: 2.580595\n",
      "  Epoch 25/50, Loss: 2.576794\n",
      "  Epoch 26/50, Loss: 2.572862\n",
      "  Epoch 27/50, Loss: 2.571614\n",
      "  Epoch 28/50, Loss: 2.567565\n",
      "  Epoch 29/50, Loss: 2.566786\n",
      "  Epoch 30/50, Loss: 2.562737\n",
      "  Epoch 31/50, Loss: 2.561781\n",
      "  Epoch 32/50, Loss: 2.558981\n",
      "  Epoch 33/50, Loss: 2.556257\n",
      "  Epoch 34/50, Loss: 2.554657\n",
      "  Epoch 35/50, Loss: 2.552829\n",
      "  Epoch 36/50, Loss: 2.551266\n",
      "  Epoch 37/50, Loss: 2.549645\n",
      "  Epoch 38/50, Loss: 2.548543\n",
      "  Epoch 39/50, Loss: 2.546019\n",
      "  Epoch 40/50, Loss: 2.545587\n",
      "  Epoch 41/50, Loss: 2.542946\n",
      "  Epoch 42/50, Loss: 2.541276\n",
      "  Epoch 43/50, Loss: 2.539896\n",
      "  Epoch 44/50, Loss: 2.538837\n",
      "  Epoch 45/50, Loss: 2.538012\n",
      "  Epoch 46/50, Loss: 2.535431\n",
      "  Epoch 47/50, Loss: 2.535390\n",
      "  Epoch 48/50, Loss: 2.534735\n",
      "  Epoch 49/50, Loss: 2.531822\n",
      "  Epoch 50/50, Loss: 2.531919\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 5/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.785902\n",
      "  Epoch 2/50, Loss: 2.753570\n",
      "  Epoch 3/50, Loss: 2.738375\n",
      "  Epoch 4/50, Loss: 2.723899\n",
      "  Epoch 5/50, Loss: 2.709782\n",
      "  Epoch 6/50, Loss: 2.697073\n",
      "  Epoch 7/50, Loss: 2.685505\n",
      "  Epoch 8/50, Loss: 2.675393\n",
      "  Epoch 9/50, Loss: 2.665062\n",
      "  Epoch 10/50, Loss: 2.655731\n",
      "  Epoch 11/50, Loss: 2.648091\n",
      "  Epoch 12/50, Loss: 2.640144\n",
      "  Epoch 13/50, Loss: 2.632771\n",
      "  Epoch 14/50, Loss: 2.627013\n",
      "  Epoch 15/50, Loss: 2.621049\n",
      "  Epoch 16/50, Loss: 2.614401\n",
      "  Epoch 17/50, Loss: 2.610492\n",
      "  Epoch 18/50, Loss: 2.605516\n",
      "  Epoch 19/50, Loss: 2.601094\n",
      "  Epoch 20/50, Loss: 2.596694\n",
      "  Epoch 21/50, Loss: 2.593245\n",
      "  Epoch 22/50, Loss: 2.589072\n",
      "  Epoch 23/50, Loss: 2.585356\n",
      "  Epoch 24/50, Loss: 2.581500\n",
      "  Epoch 25/50, Loss: 2.579017\n",
      "  Epoch 26/50, Loss: 2.576807\n",
      "  Epoch 27/50, Loss: 2.574732\n",
      "  Epoch 28/50, Loss: 2.571117\n",
      "  Epoch 29/50, Loss: 2.568752\n",
      "  Epoch 30/50, Loss: 2.566912\n",
      "  Epoch 31/50, Loss: 2.565064\n",
      "  Epoch 32/50, Loss: 2.562962\n",
      "  Epoch 33/50, Loss: 2.561360\n",
      "  Epoch 34/50, Loss: 2.559121\n",
      "  Epoch 35/50, Loss: 2.556823\n",
      "  Epoch 36/50, Loss: 2.557010\n",
      "  Epoch 37/50, Loss: 2.553665\n",
      "  Epoch 38/50, Loss: 2.551738\n",
      "  Epoch 39/50, Loss: 2.549924\n",
      "  Epoch 40/50, Loss: 2.549085\n",
      "  Epoch 41/50, Loss: 2.546933\n",
      "  Epoch 42/50, Loss: 2.546275\n",
      "  Epoch 43/50, Loss: 2.543996\n",
      "  Epoch 44/50, Loss: 2.543917\n",
      "  Epoch 45/50, Loss: 2.542755\n",
      "  Epoch 46/50, Loss: 2.540792\n",
      "  Epoch 47/50, Loss: 2.540976\n",
      "  Epoch 48/50, Loss: 2.538560\n",
      "  Epoch 49/50, Loss: 2.537376\n",
      "  Epoch 50/50, Loss: 2.536588\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namwonjin\\Documents\\Kaggle\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HybridFullStackingClassifier(meta_model=LogisticRegression(),\n",
       "                             model_defs=[(&lt;class &#x27;catboost.core.CatBoostClassifier&#x27;&gt;,\n",
       "                                          {&#x27;bootstrap_type&#x27;: &#x27;Poisson&#x27;,\n",
       "                                           &#x27;depth&#x27;: 8,\n",
       "                                           &#x27;early_stopping_rounds&#x27;: 200,\n",
       "                                           &#x27;eval_metric&#x27;: &#x27;MultiClass&#x27;,\n",
       "                                           &#x27;grow_policy&#x27;: &#x27;Depthwise&#x27;,\n",
       "                                           &#x27;iterations&#x27;: 2000, &#x27;l2_leaf_reg&#x27;: 3,\n",
       "                                           &#x27;learning_rate&#x27;: 0.05,\n",
       "                                           &#x27;loss_function&#x27;: &#x27;MultiClass&#x27;,\n",
       "                                           &#x27;random_seed&#x27;: 42, &#x27;subsample&#x27;: 0....\n",
       "                                                                                 &#x27;tof_1_v10&#x27;,\n",
       "                                                                                 &#x27;tof_1_v11&#x27;,\n",
       "                                                                                 &#x27;tof_1_v12&#x27;,\n",
       "                                                                                 &#x27;tof_1_v13&#x27;,\n",
       "                                                                                 &#x27;tof_1_v14&#x27;,\n",
       "                                                                                 &#x27;tof_1_v15&#x27;,\n",
       "                                                                                 &#x27;tof_1_v16&#x27;,\n",
       "                                                                                 &#x27;tof_1_v17&#x27;,\n",
       "                                                                                 &#x27;tof_1_v18&#x27;,\n",
       "                                                                                 &#x27;tof_1_v19&#x27;,\n",
       "                                                                                 &#x27;tof_1_v20&#x27;,\n",
       "                                                                                 &#x27;tof_1_v21&#x27;,\n",
       "                                                                                 &#x27;tof_1_v22&#x27;,\n",
       "                                                                                 &#x27;tof_1_v23&#x27;,\n",
       "                                                                                 &#x27;tof_1_v24&#x27;,\n",
       "                                                                                 &#x27;tof_1_v25&#x27;,\n",
       "                                                                                 &#x27;tof_1_v26&#x27;,\n",
       "                                                                                 &#x27;tof_1_v27&#x27;,\n",
       "                                                                                 &#x27;tof_1_v28&#x27;,\n",
       "                                                                                 &#x27;tof_1_v29&#x27;, ...]))]),\n",
       "                                        Pipeline(steps=[(&#x27;cnn_features&#x27;,\n",
       "                                                         CNNFeatureGenerator(batch_size=128,\n",
       "                                                                             epochs=50,\n",
       "                                                                             feature_dim=64,\n",
       "                                                                             num_classes=18))])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;HybridFullStackingClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>HybridFullStackingClassifier(meta_model=LogisticRegression(),\n",
       "                             model_defs=[(&lt;class &#x27;catboost.core.CatBoostClassifier&#x27;&gt;,\n",
       "                                          {&#x27;bootstrap_type&#x27;: &#x27;Poisson&#x27;,\n",
       "                                           &#x27;depth&#x27;: 8,\n",
       "                                           &#x27;early_stopping_rounds&#x27;: 200,\n",
       "                                           &#x27;eval_metric&#x27;: &#x27;MultiClass&#x27;,\n",
       "                                           &#x27;grow_policy&#x27;: &#x27;Depthwise&#x27;,\n",
       "                                           &#x27;iterations&#x27;: 2000, &#x27;l2_leaf_reg&#x27;: 3,\n",
       "                                           &#x27;learning_rate&#x27;: 0.05,\n",
       "                                           &#x27;loss_function&#x27;: &#x27;MultiClass&#x27;,\n",
       "                                           &#x27;random_seed&#x27;: 42, &#x27;subsample&#x27;: 0....\n",
       "                                                                                 &#x27;tof_1_v10&#x27;,\n",
       "                                                                                 &#x27;tof_1_v11&#x27;,\n",
       "                                                                                 &#x27;tof_1_v12&#x27;,\n",
       "                                                                                 &#x27;tof_1_v13&#x27;,\n",
       "                                                                                 &#x27;tof_1_v14&#x27;,\n",
       "                                                                                 &#x27;tof_1_v15&#x27;,\n",
       "                                                                                 &#x27;tof_1_v16&#x27;,\n",
       "                                                                                 &#x27;tof_1_v17&#x27;,\n",
       "                                                                                 &#x27;tof_1_v18&#x27;,\n",
       "                                                                                 &#x27;tof_1_v19&#x27;,\n",
       "                                                                                 &#x27;tof_1_v20&#x27;,\n",
       "                                                                                 &#x27;tof_1_v21&#x27;,\n",
       "                                                                                 &#x27;tof_1_v22&#x27;,\n",
       "                                                                                 &#x27;tof_1_v23&#x27;,\n",
       "                                                                                 &#x27;tof_1_v24&#x27;,\n",
       "                                                                                 &#x27;tof_1_v25&#x27;,\n",
       "                                                                                 &#x27;tof_1_v26&#x27;,\n",
       "                                                                                 &#x27;tof_1_v27&#x27;,\n",
       "                                                                                 &#x27;tof_1_v28&#x27;,\n",
       "                                                                                 &#x27;tof_1_v29&#x27;, ...]))]),\n",
       "                                        Pipeline(steps=[(&#x27;cnn_features&#x27;,\n",
       "                                                         CNNFeatureGenerator(batch_size=128,\n",
       "                                                                             epochs=50,\n",
       "                                                                             feature_dim=64,\n",
       "                                                                             num_classes=18))])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">meta_model: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HybridFullStackingClassifier(meta_model=LogisticRegression(),\n",
       "                             model_defs=[(<class 'catboost.core.CatBoostClassifier'>,\n",
       "                                          {'bootstrap_type': 'Poisson',\n",
       "                                           'depth': 8,\n",
       "                                           'early_stopping_rounds': 200,\n",
       "                                           'eval_metric': 'MultiClass',\n",
       "                                           'grow_policy': 'Depthwise',\n",
       "                                           'iterations': 2000, 'l2_leaf_reg': 3,\n",
       "                                           'learning_rate': 0.05,\n",
       "                                           'loss_function': 'MultiClass',\n",
       "                                           'random_seed': 42, 'subsample': 0....\n",
       "                                                                                 'tof_1_v10',\n",
       "                                                                                 'tof_1_v11',\n",
       "                                                                                 'tof_1_v12',\n",
       "                                                                                 'tof_1_v13',\n",
       "                                                                                 'tof_1_v14',\n",
       "                                                                                 'tof_1_v15',\n",
       "                                                                                 'tof_1_v16',\n",
       "                                                                                 'tof_1_v17',\n",
       "                                                                                 'tof_1_v18',\n",
       "                                                                                 'tof_1_v19',\n",
       "                                                                                 'tof_1_v20',\n",
       "                                                                                 'tof_1_v21',\n",
       "                                                                                 'tof_1_v22',\n",
       "                                                                                 'tof_1_v23',\n",
       "                                                                                 'tof_1_v24',\n",
       "                                                                                 'tof_1_v25',\n",
       "                                                                                 'tof_1_v26',\n",
       "                                                                                 'tof_1_v27',\n",
       "                                                                                 'tof_1_v28',\n",
       "                                                                                 'tof_1_v29', ...]))]),\n",
       "                                        Pipeline(steps=[('cnn_features',\n",
       "                                                         CNNFeatureGenerator(batch_size=128,\n",
       "                                                                             epochs=50,\n",
       "                                                                             feature_dim=64,\n",
       "                                                                             num_classes=18))])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = HybridFullStackingClassifier(\n",
    "    pipelines=pipelines,\n",
    "    model_defs=model_defs,\n",
    "    n_splits = CFG.folds, \n",
    "    random_state = CFG.seed,\n",
    "    meta_model=LogisticRegression(),\n",
    "    n_bins=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Polars 데이터프레임을 입력으로 학습 시작\n",
    "ensemble.fit(train_X_full, train_y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f335e581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n"
     ]
    }
   ],
   "source": [
    "test_X = test.drop(['row_id'])\n",
    "predictions = ensemble.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09e7a358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'submission.csv' 파일 생성이 완료되었습니다!\n",
      "shape: (5, 2)\n",
      "┌───────────────────┬───────────────┐\n",
      "│ row_id            ┆ gesture       │\n",
      "│ ---               ┆ ---           │\n",
      "│ str               ┆ str           │\n",
      "╞═══════════════════╪═══════════════╡\n",
      "│ SEQ_000001_000000 ┆ Text on phone │\n",
      "│ SEQ_000001_000001 ┆ Text on phone │\n",
      "│ SEQ_000001_000002 ┆ Text on phone │\n",
      "│ SEQ_000001_000003 ┆ Text on phone │\n",
      "│ SEQ_000001_000004 ┆ Text on phone │\n",
      "└───────────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "submission_df = pl.DataFrame({\n",
    "    'row_id': test['row_id'],\n",
    "    'gesture': predictions\n",
    "})\n",
    "\n",
    "# 4. CSV 파일로 저장\n",
    "submission_df.write_csv('submission.csv')\n",
    "\n",
    "print(\"\\n'submission.csv' 파일 생성이 완료되었습니다!\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
