{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c8df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    target = \"gesture\"\n",
    "    folds = 5\n",
    "    seed = 42\n",
    "    folder_path = 'csvfile/'\n",
    "    except_cols = ['row_id']\n",
    "    importance_threshold=1e-4\n",
    "    target_gestures = [\n",
    "        'Above ear - pull hair',\n",
    "        'Cheek - pinch skin',\n",
    "        'Eyebrow - pull hair',\n",
    "        'Eyelash - pull hair',\n",
    "        'Forehead - pull hairline',\n",
    "        'Forehead - scratch',\n",
    "        'Neck - pinch skin',\n",
    "        'Neck - scratch',\n",
    "        ]\n",
    "    non_target_gestures = [\n",
    "        'Write name on leg',\n",
    "        'Wave hello',\n",
    "        'Glasses on/off',\n",
    "        'Text on phone',\n",
    "        'Write name in air',\n",
    "        'Feel around in tray and pull out an object',\n",
    "        'Scratch knee/leg skin',\n",
    "        'Pull air toward your face',\n",
    "        'Drink from bottle/cup',\n",
    "        'Pinch knee/leg skin'\n",
    "        ]\n",
    "    all_gestures = target_gestures + non_target_gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ca2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import cv2\n",
    "import itertools\n",
    "import random\n",
    "from scipy.stats import zscore, skew\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin,TransformerMixin, RegressorMixin,clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, KBinsDiscretizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import norm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import itertools\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6527e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(CFG.folder_path + 'train.csv').join(pl.read_csv(CFG.folder_path + 'train_demographics.csv'), on=\"subject\", how=\"left\")\n",
    "test = pl.read_csv(CFG.folder_path + 'test.csv').join(pl.read_csv(CFG.folder_path + 'test_demographics.csv'), on=\"subject\", how=\"left\")\n",
    "tof_cols_ = [f'tof_{s}_v{p}' for s in range(1, 6) for p in range(64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f180465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contest_metric(y_true, y_pred, target_gestures):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    target_gestures = set(target_gestures)\n",
    "    \n",
    "    all_labels = sorted(list(target_gestures | {'non_target'}))\n",
    "\n",
    "    y_true_binary = np.where(np.isin(y_true, list(target_gestures)), 'target', 'non_target')\n",
    "    y_pred_binary = np.where(np.isin(y_pred, list(target_gestures)), 'target', 'non_target')\n",
    "    \n",
    "    binary_f1 = f1_score(y_true_binary, y_pred_binary, pos_label='target', average='binary')\n",
    "\n",
    "    y_true_macro = np.where(np.isin(y_true, list(target_gestures)), y_true, 'non_target')\n",
    "    y_pred_macro = np.where(np.isin(y_pred, list(target_gestures)), y_pred, 'non_target')\n",
    "\n",
    "    macro_f1 = f1_score(y_true_macro, y_pred_macro, labels=all_labels, average='macro')\n",
    "\n",
    "    final_score = (binary_f1 + macro_f1) / 2\n",
    "\n",
    "    return {\n",
    "        'binary_f1': binary_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'final_score': final_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18513d",
   "metadata": {},
   "source": [
    "# 2. Make Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e569de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Polars Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ XÏóêÏÑú self.columnsÎ•º ÏÑ†ÌÉù\n",
    "        selected_X = X.select(self.columns)\n",
    "        return selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f04d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToFDataset(Dataset):\n",
    "    \"\"\"\n",
    "    null Í∞íÏùÑ ÏõêÏ≤úÏ†ÅÏúºÎ°ú Î∞©Ïñ¥ÌïòÎèÑÎ°ù ÏàòÏ†ïÎêú ÏµúÏ¢Ö Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§\n",
    "    \"\"\"\n",
    "    def __init__(self, df, tof_cols, labels=None):\n",
    "        # --- [ÌïµÏã¨ ÏàòÏ†ï] ---\n",
    "        # Polars -> NumpyÎ°ú Î≥ÄÌôòÌïòÍ∏∞ Ï†ÑÏóê, Î™®Îì† null Í∞íÏùÑ -1.0ÏúºÎ°ú Ï±ÑÏõÅÎãàÎã§.\n",
    "        self.tof_data = (\n",
    "            df.select(tof_cols)\n",
    "            .fill_null(-1.0)\n",
    "            .to_numpy()\n",
    "            .astype(np.float32)\n",
    "        )\n",
    "        # -------------------\n",
    "        \n",
    "        # ÎßåÏïΩ Ïù¥ Îã®Í≥ÑÏóêÏÑúÎèÑ NaNÏù¥ ÏûàÎã§Î©¥, ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ ÏûêÏ≤¥Ïóê Inf Îì±Ïùò Ïù¥ÏÉÅÍ∞íÏù¥ ÏûàÎã§Îäî ÏùòÎØ∏ÏûÖÎãàÎã§.\n",
    "        if np.isnan(self.tof_data).any():\n",
    "            print(\"üö® CRITICAL: NaN detected in data even after fill_null. Check source for Inf values.\")\n",
    "            # Inf Í∞íÏùÑ -1Î°ú ÎåÄÏ≤¥\n",
    "            self.tof_data = np.nan_to_num(self.tof_data, nan=-1.0, posinf=-1.0, neginf=-1.0)\n",
    "\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tof_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tof_vector = self.tof_data[idx]\n",
    "        tof_image = tof_vector.reshape(5, 8, 8)\n",
    "        \n",
    "        # Ïù¥ Îã®Í≥ÑÏóêÏÑúÎäî -1Îßå Ï°¥Ïû¨ÌïòÎØÄÎ°ú, Ï†ïÍ∑úÌôî Î°úÏßÅÏùÄ Í∑∏ÎåÄÎ°ú Ïú†ÏßÄÌï©ÎãàÎã§.\n",
    "        valid_data_mask = (tof_image != -1.0)\n",
    "        normalized_image = np.where(valid_data_mask, tof_image / 254.0, 0)\n",
    "        final_image = np.where(valid_data_mask, normalized_image, -1.0)\n",
    "        \n",
    "        tof_tensor = torch.tensor(final_image, dtype=torch.float32)\n",
    "\n",
    "        if self.labels is not None:\n",
    "            return tof_tensor, self.labels[idx]\n",
    "        else:\n",
    "            return tof_tensor\n",
    "\n",
    "# CNN Î™®Îç∏ ÌÅ¥ÎûòÏä§\n",
    "class ToF_CNN_Extractor(nn.Module):\n",
    "    def __init__(self, num_classes, feature_dim=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # Input: (N, 5, 8, 8)\n",
    "            nn.Conv2d(in_channels=5, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Flatten(), # -> (N, 64 * 2 * 2) = (N, 256)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 2 * 2, feature_dim), # <-- 64*2*2 ÏóêÏÑú 128*2*2 (Ï¶â, 512)Î°ú ÏàòÏ†ï\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(feature_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 2 * 2, feature_dim),\n",
    "            nn.LeakyReLU(negative_slope=0.01), # ReLU -> LeakyReLU\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(feature_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# CNNFeatureGenerator ÌÅ¥ÎûòÏä§ ÏàòÏ†ï\n",
    "# -----------------------------------------------------\n",
    "class CNNFeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_classes, feature_dim=256, epochs=5, batch_size=64, lr=1e-4, verbose=True):\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_dim = feature_dim\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # ToF_CNN_Extractor Î™®Îç∏ÏùÄ Ïù¥Ï†ÑÏóê ÏàòÏ†ïÌïú 'Îçî Ïª§ÏßÑ' Î≤ÑÏ†ÑÏùÑ ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
    "        self.model = ToF_CNN_Extractor(self.num_classes, self.feature_dim).to(self.device)\n",
    "        \n",
    "        self.tof_cols_ = [f'tof_{s}_v{p}' for s in range(1, 6) for p in range(64)]\n",
    "        \n",
    "        # --- [ÌïµÏã¨ ÏàòÏ†ï Î∂ÄÎ∂Ñ] ---\n",
    "        # Flatten ÌõÑÏùò Ïã§Ï†ú ÌîºÏ≤ò Í∞úÏàòÏù∏ 512Ïóê ÎßûÏ∂∞ ÌîºÏ≤ò Ïù¥Î¶ÑÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.\n",
    "        self.flattened_dim_ = 64 * 2 * 2  # 512\n",
    "        self.feature_names_out_ = [f'cnn_feat_{i}' for i in range(self.flattened_dim_)]\n",
    "        # ------------------------\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # fit Î©îÏÑúÎìúÎäî Ïù¥Ï†ÑÍ≥º ÎèôÏùºÌï©ÎãàÎã§.\n",
    "        if self.verbose:\n",
    "            print(f\"CNN Feature Generator: Starting training on {self.device} for {self.epochs} epochs...\")\n",
    "        # (Ïù¥Ìïò ÏÉùÎûµ)\n",
    "        \n",
    "        train_dataset = ToFDataset(X, self.tof_cols_, labels=y)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "            for inputs, labels in train_loader:\n",
    "                # labels.to() Ìò∏Ï∂ú Ïãú dtype=torch.longÏùÑ Ï∂îÍ∞Ä\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device, dtype=torch.long) \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels) # Ïù¥Ï†ú Ï†ïÏÉÅ ÏûëÎèô\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            if self.verbose:\n",
    "                if len(train_loader) > 0:\n",
    "                    avg_loss = total_loss / len(train_loader)\n",
    "                    print(f\"  Epoch {epoch+1}/{self.epochs}, Loss: {avg_loss:.6f}\")\n",
    "                else:\n",
    "                    print(f\"  Epoch {epoch+1}/{self.epochs}, train_loader is empty.\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # transform Î©îÏÑúÎìúÎäî Ïù¥Ï†ÑÍ≥º ÎèôÏùºÌï©ÎãàÎã§.\n",
    "        if self.verbose:\n",
    "            print(\"CNN Feature Generator: Extracting features...\")\n",
    "        self.model.eval()\n",
    "        transform_dataset = ToFDataset(X, self.tof_cols_, labels=None)\n",
    "        transform_loader = DataLoader(transform_dataset, batch_size=self.batch_size * 2, shuffle=False)\n",
    "        all_features = []\n",
    "        with torch.no_grad():\n",
    "            for inputs in transform_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                features = self.model.feature_extractor(inputs)\n",
    "                all_features.append(features.cpu().numpy())\n",
    "        cnn_features_np = np.concatenate(all_features, axis=0)\n",
    "        \n",
    "        # Ïù¥Ï†ú Ïä§ÌÇ§Îßà(512)ÏôÄ Îç∞Ïù¥ÌÑ∞(512)Ïùò Ï∞®ÏõêÏù¥ ÏùºÏπòÌï©ÎãàÎã§.\n",
    "        return pl.DataFrame(cnn_features_np, schema=self.get_feature_names_out())\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return self.feature_names_out_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43326768",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0137c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFullStackingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    # __init__ Î©îÏÜåÎìúÎäî Î≥ÄÍ≤Ω ÏóÜÏùå (Ïù¥Ï†ÑÍ≥º ÎèôÏùº)\n",
    "    def __init__(self, pipelines, model_defs, meta_model,\n",
    "                 n_splits=CFG.folds, random_state=CFG.seed, verbose=True,\n",
    "                 stratify_feature=None, n_bins=10):\n",
    "        self.pipelines = pipelines\n",
    "        self.model_defs = model_defs\n",
    "        self.meta_model = meta_model\n",
    "        self.n_splits = n_splits\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.stratify_feature = stratify_feature\n",
    "        self.n_bins = n_bins\n",
    "        self.fitted_models_ = []\n",
    "        self.label_encoder_ = LabelEncoder()\n",
    "        self.classes_ = None\n",
    "        self.feature_names_in_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # ... (ÏÉÅÎã® Î∂ÄÎ∂ÑÏùÄ Ïù¥Ï†Ñ Polars Î≤ÑÏ†ÑÍ≥º ÎèôÏùº) ...\n",
    "        if not isinstance(X, pl.DataFrame):\n",
    "            raise TypeError(\"Input X must be a Polars DataFrame.\")\n",
    "        if not isinstance(y, pl.Series):\n",
    "            raise TypeError(\"Input y must be a Polars Series.\")\n",
    "\n",
    "        self.feature_names_in_ = X.columns\n",
    "        y_encoded = self.label_encoder_.fit_transform(y.to_numpy())\n",
    "        self.classes_ = self.label_encoder_.classes_\n",
    "\n",
    "        n_samples = X.height\n",
    "        n_classes_out = len(self.classes_) if len(self.classes_) > 2 else 1\n",
    "        total_base_models = len(self.pipelines) * len(self.model_defs)\n",
    "        meta_features = np.zeros((n_samples, total_base_models * n_classes_out))\n",
    "\n",
    "        stratify_values = y_encoded\n",
    "        if self.stratify_feature and self.stratify_feature in X.columns:\n",
    "            binner = KBinsDiscretizer(n_bins=self.n_bins, encode='ordinal', strategy='quantile')\n",
    "            stratify_values = binner.fit_transform(X.select(self.stratify_feature).to_pandas()).astype(int).flatten()\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        base_model_counter = 0\n",
    "        for pi, pipeline_def in enumerate(self.pipelines):\n",
    "            for mi, (model_cls, model_params) in enumerate(self.model_defs):\n",
    "                if self.verbose:\n",
    "                    print(f\"\\nTraining Pipeline {pi+1} + Model {model_cls.__name__}\")\n",
    "\n",
    "                oof_preds = np.zeros((n_samples, n_classes_out))\n",
    "                fold_specific_models = []\n",
    "\n",
    "                for fold, (train_idx, val_idx) in enumerate(kf.split(np.zeros(n_samples), stratify_values)):\n",
    "                    if self.verbose: print(f\"  Fold {fold+1}/{self.n_splits}...\")\n",
    "                    \n",
    "                    X_train, X_val = X.slice(train_idx[0], len(train_idx)), X.slice(val_idx[0], len(val_idx))\n",
    "                    y_train_fold, y_val_fold = y_encoded[train_idx], y_encoded[val_idx]\n",
    "                    \n",
    "                    pipeline = clone(pipeline_def).fit(X_train, y_train_fold)\n",
    "                    \n",
    "                    X_train_trans = pipeline.transform(X_train)\n",
    "                    X_val_trans = pipeline.transform(X_val)\n",
    "\n",
    "                    cat_cols = X_train_trans.select(cs.string() | cs.categorical()).columns\n",
    "                    \n",
    "                    model_params_copy = model_params.copy()\n",
    "                    model_name = model_cls.__name__.lower()\n",
    "                    \n",
    "                    if \"catboost\" in model_name:\n",
    "                        model_params_copy[\"cat_features\"] = cat_cols\n",
    "                    elif \"xgb\" in model_name:\n",
    "                        model_params_copy[\"enable_categorical\"] = True\n",
    "                    \n",
    "                    model = model_cls(**model_params_copy)\n",
    "                    \n",
    "                    # [PANDAS-CONVERSION] Î™®Îç∏ ÌïôÏäµ ÏßÅÏ†ÑÏóê PandasÎ°ú Î≥ÄÌôò\n",
    "                    X_train_pd = X_train_trans.to_pandas()\n",
    "                    X_val_pd = X_val_trans.to_pandas()\n",
    "\n",
    "                    if \"lgbm\" in model_name:\n",
    "                         # LightGBMÏùÄ category ÌÉÄÏûÖÏùÑ ÏßÅÏ†ë ÏßÄÏõê\n",
    "                         X_train_pd[cat_cols] = X_train_pd[cat_cols].astype(\"category\")\n",
    "                         X_val_pd[cat_cols] = X_val_pd[cat_cols].astype(\"category\")\n",
    "                         model.fit(X_train_pd, y_train_fold) \n",
    "                    else:\n",
    "                         model.fit(X_train_pd, y_train_fold)\n",
    "                    \n",
    "                    proba_preds = model.predict_proba(X_val_pd) # Î≥ÄÌôòÎêú Pandas Îç∞Ïù¥ÌÑ∞Î°ú ÏòàÏ∏°\n",
    "                    \n",
    "                    if n_classes_out == 1:\n",
    "                        oof_preds[val_idx] = proba_preds[:, 1].reshape(-1, 1)\n",
    "                    else:\n",
    "                        oof_preds[val_idx] = proba_preds\n",
    "                    \n",
    "                    fold_specific_models.append((pipeline, model))\n",
    "                \n",
    "                start_col, end_col = base_model_counter, base_model_counter + n_classes_out\n",
    "                meta_features[:, start_col:end_col] = oof_preds\n",
    "                base_model_counter += n_classes_out\n",
    "                \n",
    "                self.fitted_models_.append(fold_specific_models)\n",
    "\n",
    "        self.meta_model.fit(meta_features, y_encoded)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not isinstance(X, pl.DataFrame):\n",
    "            raise TypeError(\"Input X must be a Polars DataFrame.\")\n",
    "        \n",
    "        n_samples = X.height\n",
    "        n_classes_out = len(self.classes_) if len(self.classes_) > 2 else 1\n",
    "        total_base_models = len(self.fitted_models_)\n",
    "        meta_X_test = np.zeros((n_samples, total_base_models * n_classes_out))\n",
    "        \n",
    "        current_meta_col_idx = 0\n",
    "        for fold_models in self.fitted_models_:\n",
    "            fold_preds = []\n",
    "            for pipeline, model in fold_models:\n",
    "                X_trans = pipeline.transform(X)\n",
    "\n",
    "                # [PANDAS-CONVERSION] Î™®Îç∏ ÏòàÏ∏° ÏßÅÏ†ÑÏóê PandasÎ°ú Î≥ÄÌôò\n",
    "                X_trans_pd = X_trans.to_pandas()\n",
    "                \n",
    "                # LGBMÏùÑ ÏúÑÌïú Î≤îÏ£ºÌòï ÌÉÄÏûÖ Î≥ÄÌôò\n",
    "                cat_cols = X_trans.select(cs.string() | cs.categorical()).columns\n",
    "                if cat_cols:\n",
    "                    X_trans_pd[cat_cols] = X_trans_pd[cat_cols].astype(\"category\")\n",
    "\n",
    "                fold_preds.append(model.predict_proba(X_trans_pd))\n",
    "\n",
    "            averaged_preds = np.mean(np.array(fold_preds), axis=0)\n",
    "            \n",
    "            start_col, end_col = current_meta_col_idx, current_meta_col_idx + n_classes_out\n",
    "            if n_classes_out == 1:\n",
    "                meta_X_test[:, start_col:end_col] = averaged_preds[:, 1].reshape(-1, 1)\n",
    "            else:\n",
    "                meta_X_test[:, start_col:end_col] = averaged_preds\n",
    "            current_meta_col_idx += n_classes_out\n",
    "            \n",
    "        return self.meta_model.predict_proba(meta_X_test)\n",
    "    \n",
    "    # predictÏôÄ score Î©îÏÜåÎìúÎäî Î≥ÄÍ≤Ω ÏóÜÏùå\n",
    "    def predict(self, X):\n",
    "        final_proba = self.predict_proba(X)\n",
    "        if len(self.classes_) == 2:\n",
    "            predictions_encoded = (final_proba[:, 1] >= 0.5).astype(int)\n",
    "        else:\n",
    "            predictions_encoded = np.argmax(final_proba, axis=1)\n",
    "        return self.label_encoder_.inverse_transform(predictions_encoded)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        # yÍ∞Ä polars seriesÏùº Ïàò ÏûàÏúºÎØÄÎ°ú numpyÎ°ú Î≥ÄÌôò\n",
    "        y_true = y.to_numpy() if isinstance(y, pl.Series) else np.array(y)\n",
    "        return calculate_contest_metric(y_true, y_pred, CFG.target_gestures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_column_selector_pipeline(columns):\n",
    "    return Pipeline([\n",
    "        ('column_selector', ColumnSelector(columns))\n",
    "    ])\n",
    "\n",
    "def build_cnn_feature_pipeline(num_classes, \n",
    "                               feature_dim=64, \n",
    "                               epochs=50, \n",
    "                               batch_size=128, \n",
    "                               lr=1e-3, \n",
    "                               verbose=True):\n",
    "    return Pipeline([\n",
    "        ('cnn_features', CNNFeatureGenerator(\n",
    "            num_classes=num_classes, \n",
    "            feature_dim=feature_dim,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            lr=lr,\n",
    "            verbose=verbose\n",
    "        ))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfca777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_full = train.drop(['row_id', CFG.target])\n",
    "train_y_full = train[CFG.target]\n",
    "train_X_full_pd = train_X_full.to_pandas()\n",
    "train_y_full_pd = train_y_full.to_pandas()\n",
    "\n",
    "X_train_pd, X_val_pd, y_train_pd, y_val_pd = train_test_split(\n",
    "    train_X_full_pd, train_y_full_pd,\n",
    "    test_size=0.2,\n",
    "    random_state=CFG.seed,\n",
    "    stratify=train_y_full_pd\n",
    ")\n",
    "X_train_20 = pl.from_pandas(X_train_pd)\n",
    "X_val_20 = pl.from_pandas(X_val_pd)\n",
    "y_train_20 = pl.from_pandas(y_train_pd)\n",
    "y_val_20 = pl.from_pandas(y_val_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d691d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = build_column_selector_pipeline(columns=tof_cols_)\n",
    "pipeline2 = build_cnn_feature_pipeline(num_classes=len(CFG.all_gestures))\n",
    "pipelines = [pipeline1,pipeline2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297b34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_defs = [\n",
    "    (CatBoostClassifier, {\n",
    "        'iterations': 2000,\n",
    "        'learning_rate': 0.05,\n",
    "        'depth': 8,\n",
    "        'loss_function': 'MultiClass',\n",
    "        'l2_leaf_reg': 3,\n",
    "        'random_seed': CFG.seed,\n",
    "        'eval_metric': 'MultiClass',\n",
    "        'early_stopping_rounds': 200,\n",
    "        'verbose': 0,\n",
    "        'task_type': 'GPU',\n",
    "        'bootstrap_type': 'Poisson',\n",
    "        'grow_policy': 'Depthwise',\n",
    "        'subsample': 0.8\n",
    "    }),\n",
    "    (XGBClassifier, {\n",
    "        'max_depth': 8,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'subsample': 0.9,\n",
    "        'n_estimators': 2000,\n",
    "        'learning_rate': 0.05,\n",
    "        'gamma': 0.01,\n",
    "        'reg_alpha': 2.0,\n",
    "        'reg_lambda': 1.5,\n",
    "        'max_delta_step': 2,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'random_state': CFG.seed,\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "    }),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ad340b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN ÌîºÏ≤ò ÏÉùÏÑ±Í∏∞ ÌïôÏäµ...\n",
      "CNN Feature Generator: Starting training on cuda for 10 epochs...\n",
      "  Epoch 1/10, Loss: 2.353439\n",
      "  Epoch 2/10, Loss: 2.138539\n",
      "  Epoch 3/10, Loss: 2.056614\n",
      "  Epoch 4/10, Loss: 2.004709\n",
      "  Epoch 5/10, Loss: 1.968892\n",
      "  Epoch 6/10, Loss: 1.940922\n",
      "  Epoch 7/10, Loss: 1.918660\n",
      "  Epoch 8/10, Loss: 1.899386\n",
      "  Epoch 9/10, Loss: 1.883201\n",
      "  Epoch 10/10, Loss: 1.869609\n",
      "ÌïôÏäµ Î∞è Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÌîºÏ≤ò Ï∂îÏ∂ú Ï§ë...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "XGBoost Î™®Îç∏ ÌïôÏäµ Ï§ë...\n",
      "ÏòàÏ∏° Î∞è ÌèâÍ∞Ä Ï§ë...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namwonjin\\Documents\\Kaggle\\venv\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:55:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌÖåÏä§Ìä∏ 4 ÏµúÏ¢Ö Ï†êÏàò: 0.8193\n",
      "(Binary F1: 0.8967, Macro F1: 0.7420)\n"
     ]
    }
   ],
   "source": [
    "# 1. Î†àÏù¥Î∏î Ïù∏ÏΩîÎî© (Ïù¥ÎØ∏ Ïù¥Ï†Ñ Îã®Í≥ÑÏóêÏÑú ÏàòÌñâÌñàÎã§Î©¥ ÏÉùÎûµ Í∞ÄÎä•)\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train_20)\n",
    "y_val_encoded = le.transform(y_val_20)\n",
    "\n",
    "# 2. ÌååÏù¥ÌîÑÎùºÏù∏ Î∞è Î™®Îç∏ Ï†ïÏùò\n",
    "# CNNFeatureGeneratorÎäî Ïû¨ÏÇ¨Ïö©ÌïòÍ±∞ÎÇò ÏÉàÎ°ú ÏÉùÏÑ±Ìï† Ïàò ÏûàÏäµÎãàÎã§. Ïó¨Í∏∞ÏÑúÎäî ÏÉàÎ°ú ÏÉùÏÑ±Ìï©ÎãàÎã§.\n",
    "cnn_pipeline_xgb = CNNFeatureGenerator(\n",
    "    num_classes=len(CFG.all_gestures),\n",
    "    feature_dim=64,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    lr=1e-4,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "xgb_model_cnn = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=CFG.seed,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    ")\n",
    "\n",
    "# 3. CNN ÌîºÏ≤ò ÏÉùÏÑ± Î∞è Î≥ÄÌôò\n",
    "print(\"CNN ÌîºÏ≤ò ÏÉùÏÑ±Í∏∞ ÌïôÏäµ...\")\n",
    "cnn_pipeline_xgb.fit(X_train_20, y_train_encoded)\n",
    "\n",
    "print(\"ÌïôÏäµ Î∞è Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÌîºÏ≤ò Ï∂îÏ∂ú Ï§ë...\")\n",
    "X_train_cnn_xgb = cnn_pipeline_xgb.transform(X_train_20)\n",
    "X_val_cnn_xgb = cnn_pipeline_xgb.transform(X_val_20)\n",
    "\n",
    "# 4. XGBoost Î™®Îç∏ ÌïôÏäµ\n",
    "print(\"XGBoost Î™®Îç∏ ÌïôÏäµ Ï§ë...\")\n",
    "xgb_model_cnn.fit(X_train_cnn_xgb.to_pandas(), y_train_encoded)\n",
    "\n",
    "# 5. ÏòàÏ∏° Î∞è ÌèâÍ∞Ä\n",
    "print(\"ÏòàÏ∏° Î∞è ÌèâÍ∞Ä Ï§ë...\")\n",
    "y_pred_encoded = xgb_model_cnn.predict(X_val_cnn_xgb.to_pandas())\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "score = calculate_contest_metric(y_val_20.to_numpy(), y_pred, CFG.target_gestures)\n",
    "\n",
    "print(f\"ÌÖåÏä§Ìä∏ 4 ÏµúÏ¢Ö Ï†êÏàò: {score['final_score']:.4f}\")\n",
    "print(f\"(Binary F1: {score['binary_f1']:.4f}, Macro F1: {score['macro_f1']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8fb526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Pipeline 1 + Model CatBoostClassifier\n",
      "  Fold 1/5...\n",
      "  Fold 2/5...\n",
      "  Fold 3/5...\n",
      "  Fold 4/5...\n",
      "  Fold 5/5...\n",
      "\n",
      "Training Pipeline 1 + Model XGBClassifier\n",
      "  Fold 1/5...\n",
      "  Fold 2/5...\n",
      "  Fold 3/5...\n",
      "  Fold 4/5...\n",
      "  Fold 5/5...\n",
      "\n",
      "Training Pipeline 2 + Model CatBoostClassifier\n",
      "  Fold 1/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.784440\n",
      "  Epoch 2/50, Loss: 2.751245\n",
      "  Epoch 3/50, Loss: 2.736000\n",
      "  Epoch 4/50, Loss: 2.721005\n",
      "  Epoch 5/50, Loss: 2.707359\n",
      "  Epoch 6/50, Loss: 2.694403\n",
      "  Epoch 7/50, Loss: 2.682366\n",
      "  Epoch 8/50, Loss: 2.671793\n",
      "  Epoch 9/50, Loss: 2.661504\n",
      "  Epoch 10/50, Loss: 2.652891\n",
      "  Epoch 11/50, Loss: 2.644945\n",
      "  Epoch 12/50, Loss: 2.636849\n",
      "  Epoch 13/50, Loss: 2.630491\n",
      "  Epoch 14/50, Loss: 2.624812\n",
      "  Epoch 15/50, Loss: 2.617692\n",
      "  Epoch 16/50, Loss: 2.612284\n",
      "  Epoch 17/50, Loss: 2.607305\n",
      "  Epoch 18/50, Loss: 2.602419\n",
      "  Epoch 19/50, Loss: 2.597887\n",
      "  Epoch 20/50, Loss: 2.593732\n",
      "  Epoch 21/50, Loss: 2.590371\n",
      "  Epoch 22/50, Loss: 2.586096\n",
      "  Epoch 23/50, Loss: 2.582743\n",
      "  Epoch 24/50, Loss: 2.580290\n",
      "  Epoch 25/50, Loss: 2.576913\n",
      "  Epoch 26/50, Loss: 2.574104\n",
      "  Epoch 27/50, Loss: 2.570368\n",
      "  Epoch 28/50, Loss: 2.568428\n",
      "  Epoch 29/50, Loss: 2.567077\n",
      "  Epoch 30/50, Loss: 2.563439\n",
      "  Epoch 31/50, Loss: 2.561718\n",
      "  Epoch 32/50, Loss: 2.559836\n",
      "  Epoch 33/50, Loss: 2.556986\n",
      "  Epoch 34/50, Loss: 2.554043\n",
      "  Epoch 35/50, Loss: 2.553088\n",
      "  Epoch 36/50, Loss: 2.551787\n",
      "  Epoch 37/50, Loss: 2.550968\n",
      "  Epoch 38/50, Loss: 2.548749\n",
      "  Epoch 39/50, Loss: 2.546555\n",
      "  Epoch 40/50, Loss: 2.545296\n",
      "  Epoch 41/50, Loss: 2.543905\n",
      "  Epoch 42/50, Loss: 2.542755\n",
      "  Epoch 43/50, Loss: 2.540513\n",
      "  Epoch 44/50, Loss: 2.539632\n",
      "  Epoch 45/50, Loss: 2.538804\n",
      "  Epoch 46/50, Loss: 2.537113\n",
      "  Epoch 47/50, Loss: 2.535698\n",
      "  Epoch 48/50, Loss: 2.535891\n",
      "  Epoch 49/50, Loss: 2.533731\n",
      "  Epoch 50/50, Loss: 2.532574\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 2/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.786142\n",
      "  Epoch 2/50, Loss: 2.753119\n",
      "  Epoch 3/50, Loss: 2.737663\n",
      "  Epoch 4/50, Loss: 2.723820\n",
      "  Epoch 5/50, Loss: 2.710859\n",
      "  Epoch 6/50, Loss: 2.698376\n",
      "  Epoch 7/50, Loss: 2.686079\n",
      "  Epoch 8/50, Loss: 2.676078\n",
      "  Epoch 9/50, Loss: 2.667047\n",
      "  Epoch 10/50, Loss: 2.657396\n",
      "  Epoch 11/50, Loss: 2.648990\n",
      "  Epoch 12/50, Loss: 2.641629\n",
      "  Epoch 13/50, Loss: 2.634344\n",
      "  Epoch 14/50, Loss: 2.627215\n",
      "  Epoch 15/50, Loss: 2.623078\n",
      "  Epoch 16/50, Loss: 2.616620\n",
      "  Epoch 17/50, Loss: 2.610494\n",
      "  Epoch 18/50, Loss: 2.607054\n",
      "  Epoch 19/50, Loss: 2.602564\n",
      "  Epoch 20/50, Loss: 2.597404\n",
      "  Epoch 21/50, Loss: 2.594220\n",
      "  Epoch 22/50, Loss: 2.590053\n",
      "  Epoch 23/50, Loss: 2.587401\n",
      "  Epoch 24/50, Loss: 2.583282\n",
      "  Epoch 25/50, Loss: 2.580181\n",
      "  Epoch 26/50, Loss: 2.576961\n",
      "  Epoch 27/50, Loss: 2.573712\n",
      "  Epoch 28/50, Loss: 2.572476\n",
      "  Epoch 29/50, Loss: 2.568617\n",
      "  Epoch 30/50, Loss: 2.566381\n",
      "  Epoch 31/50, Loss: 2.564202\n",
      "  Epoch 32/50, Loss: 2.562096\n",
      "  Epoch 33/50, Loss: 2.559896\n",
      "  Epoch 34/50, Loss: 2.558639\n",
      "  Epoch 35/50, Loss: 2.556129\n",
      "  Epoch 36/50, Loss: 2.554672\n",
      "  Epoch 37/50, Loss: 2.552446\n",
      "  Epoch 38/50, Loss: 2.550160\n",
      "  Epoch 39/50, Loss: 2.548817\n",
      "  Epoch 40/50, Loss: 2.547096\n",
      "  Epoch 41/50, Loss: 2.546216\n",
      "  Epoch 42/50, Loss: 2.544449\n",
      "  Epoch 43/50, Loss: 2.542381\n",
      "  Epoch 44/50, Loss: 2.540728\n",
      "  Epoch 45/50, Loss: 2.540219\n",
      "  Epoch 46/50, Loss: 2.538448\n",
      "  Epoch 47/50, Loss: 2.537721\n",
      "  Epoch 48/50, Loss: 2.535401\n",
      "  Epoch 49/50, Loss: 2.535216\n",
      "  Epoch 50/50, Loss: 2.534107\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 3/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.784078\n",
      "  Epoch 2/50, Loss: 2.753983\n",
      "  Epoch 3/50, Loss: 2.738161\n",
      "  Epoch 4/50, Loss: 2.723739\n",
      "  Epoch 5/50, Loss: 2.709938\n",
      "  Epoch 6/50, Loss: 2.697438\n",
      "  Epoch 7/50, Loss: 2.684469\n",
      "  Epoch 8/50, Loss: 2.674650\n",
      "  Epoch 9/50, Loss: 2.664122\n",
      "  Epoch 10/50, Loss: 2.655800\n",
      "  Epoch 11/50, Loss: 2.646977\n",
      "  Epoch 12/50, Loss: 2.639399\n",
      "  Epoch 13/50, Loss: 2.631451\n",
      "  Epoch 14/50, Loss: 2.625718\n",
      "  Epoch 15/50, Loss: 2.620377\n",
      "  Epoch 16/50, Loss: 2.613528\n",
      "  Epoch 17/50, Loss: 2.608159\n",
      "  Epoch 18/50, Loss: 2.603764\n",
      "  Epoch 19/50, Loss: 2.599051\n",
      "  Epoch 20/50, Loss: 2.593903\n",
      "  Epoch 21/50, Loss: 2.591625\n",
      "  Epoch 22/50, Loss: 2.586668\n",
      "  Epoch 23/50, Loss: 2.583995\n",
      "  Epoch 24/50, Loss: 2.580257\n",
      "  Epoch 25/50, Loss: 2.577259\n",
      "  Epoch 26/50, Loss: 2.575150\n",
      "  Epoch 27/50, Loss: 2.571395\n",
      "  Epoch 28/50, Loss: 2.568651\n",
      "  Epoch 29/50, Loss: 2.567423\n",
      "  Epoch 30/50, Loss: 2.564719\n",
      "  Epoch 31/50, Loss: 2.561618\n",
      "  Epoch 32/50, Loss: 2.559159\n",
      "  Epoch 33/50, Loss: 2.557440\n",
      "  Epoch 34/50, Loss: 2.555683\n",
      "  Epoch 35/50, Loss: 2.553306\n",
      "  Epoch 36/50, Loss: 2.552773\n",
      "  Epoch 37/50, Loss: 2.550431\n",
      "  Epoch 38/50, Loss: 2.548860\n",
      "  Epoch 39/50, Loss: 2.547006\n",
      "  Epoch 40/50, Loss: 2.544912\n",
      "  Epoch 41/50, Loss: 2.544051\n",
      "  Epoch 42/50, Loss: 2.542156\n",
      "  Epoch 43/50, Loss: 2.541038\n",
      "  Epoch 44/50, Loss: 2.539310\n",
      "  Epoch 45/50, Loss: 2.538306\n",
      "  Epoch 46/50, Loss: 2.537838\n",
      "  Epoch 47/50, Loss: 2.536083\n",
      "  Epoch 48/50, Loss: 2.535519\n",
      "  Epoch 49/50, Loss: 2.532977\n",
      "  Epoch 50/50, Loss: 2.532768\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 4/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.781847\n",
      "  Epoch 2/50, Loss: 2.750618\n",
      "  Epoch 3/50, Loss: 2.734823\n",
      "  Epoch 4/50, Loss: 2.720772\n",
      "  Epoch 5/50, Loss: 2.707485\n",
      "  Epoch 6/50, Loss: 2.695265\n",
      "  Epoch 7/50, Loss: 2.683891\n",
      "  Epoch 8/50, Loss: 2.672582\n",
      "  Epoch 9/50, Loss: 2.663323\n",
      "  Epoch 10/50, Loss: 2.654578\n",
      "  Epoch 11/50, Loss: 2.646242\n",
      "  Epoch 12/50, Loss: 2.639369\n",
      "  Epoch 13/50, Loss: 2.631545\n",
      "  Epoch 14/50, Loss: 2.625575\n",
      "  Epoch 15/50, Loss: 2.620853\n",
      "  Epoch 16/50, Loss: 2.614394\n",
      "  Epoch 17/50, Loss: 2.610402\n",
      "  Epoch 18/50, Loss: 2.605590\n",
      "  Epoch 19/50, Loss: 2.601772\n",
      "  Epoch 20/50, Loss: 2.596839\n",
      "  Epoch 21/50, Loss: 2.593173\n",
      "  Epoch 22/50, Loss: 2.589876\n",
      "  Epoch 23/50, Loss: 2.586862\n",
      "  Epoch 24/50, Loss: 2.582002\n",
      "  Epoch 25/50, Loss: 2.579542\n",
      "  Epoch 26/50, Loss: 2.576469\n",
      "  Epoch 27/50, Loss: 2.574024\n",
      "  Epoch 28/50, Loss: 2.571350\n",
      "  Epoch 29/50, Loss: 2.568766\n",
      "  Epoch 30/50, Loss: 2.567035\n",
      "  Epoch 31/50, Loss: 2.563252\n",
      "  Epoch 32/50, Loss: 2.563770\n",
      "  Epoch 33/50, Loss: 2.561554\n",
      "  Epoch 34/50, Loss: 2.559478\n",
      "  Epoch 35/50, Loss: 2.556719\n",
      "  Epoch 36/50, Loss: 2.555793\n",
      "  Epoch 37/50, Loss: 2.553582\n",
      "  Epoch 38/50, Loss: 2.551516\n",
      "  Epoch 39/50, Loss: 2.550423\n",
      "  Epoch 40/50, Loss: 2.549596\n",
      "  Epoch 41/50, Loss: 2.547410\n",
      "  Epoch 42/50, Loss: 2.546681\n",
      "  Epoch 43/50, Loss: 2.545050\n",
      "  Epoch 44/50, Loss: 2.542885\n",
      "  Epoch 45/50, Loss: 2.540811\n",
      "  Epoch 46/50, Loss: 2.540926\n",
      "  Epoch 47/50, Loss: 2.540170\n",
      "  Epoch 48/50, Loss: 2.537997\n",
      "  Epoch 49/50, Loss: 2.537087\n",
      "  Epoch 50/50, Loss: 2.536327\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 5/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.780800\n",
      "  Epoch 2/50, Loss: 2.751819\n",
      "  Epoch 3/50, Loss: 2.737492\n",
      "  Epoch 4/50, Loss: 2.723290\n",
      "  Epoch 5/50, Loss: 2.709673\n",
      "  Epoch 6/50, Loss: 2.696761\n",
      "  Epoch 7/50, Loss: 2.685608\n",
      "  Epoch 8/50, Loss: 2.674672\n",
      "  Epoch 9/50, Loss: 2.665408\n",
      "  Epoch 10/50, Loss: 2.656045\n",
      "  Epoch 11/50, Loss: 2.647486\n",
      "  Epoch 12/50, Loss: 2.640202\n",
      "  Epoch 13/50, Loss: 2.633530\n",
      "  Epoch 14/50, Loss: 2.627289\n",
      "  Epoch 15/50, Loss: 2.621527\n",
      "  Epoch 16/50, Loss: 2.615698\n",
      "  Epoch 17/50, Loss: 2.610704\n",
      "  Epoch 18/50, Loss: 2.606300\n",
      "  Epoch 19/50, Loss: 2.600663\n",
      "  Epoch 20/50, Loss: 2.596765\n",
      "  Epoch 21/50, Loss: 2.592313\n",
      "  Epoch 22/50, Loss: 2.589569\n",
      "  Epoch 23/50, Loss: 2.585758\n",
      "  Epoch 24/50, Loss: 2.583618\n",
      "  Epoch 25/50, Loss: 2.579265\n",
      "  Epoch 26/50, Loss: 2.577310\n",
      "  Epoch 27/50, Loss: 2.573559\n",
      "  Epoch 28/50, Loss: 2.571643\n",
      "  Epoch 29/50, Loss: 2.568550\n",
      "  Epoch 30/50, Loss: 2.566380\n",
      "  Epoch 31/50, Loss: 2.564247\n",
      "  Epoch 32/50, Loss: 2.562969\n",
      "  Epoch 33/50, Loss: 2.559456\n",
      "  Epoch 34/50, Loss: 2.558289\n",
      "  Epoch 35/50, Loss: 2.557516\n",
      "  Epoch 36/50, Loss: 2.553396\n",
      "  Epoch 37/50, Loss: 2.552629\n",
      "  Epoch 38/50, Loss: 2.551341\n",
      "  Epoch 39/50, Loss: 2.549967\n",
      "  Epoch 40/50, Loss: 2.549204\n",
      "  Epoch 41/50, Loss: 2.547204\n",
      "  Epoch 42/50, Loss: 2.546362\n",
      "  Epoch 43/50, Loss: 2.544970\n",
      "  Epoch 44/50, Loss: 2.542019\n",
      "  Epoch 45/50, Loss: 2.540681\n",
      "  Epoch 46/50, Loss: 2.540508\n",
      "  Epoch 47/50, Loss: 2.539143\n",
      "  Epoch 48/50, Loss: 2.538091\n",
      "  Epoch 49/50, Loss: 2.536053\n",
      "  Epoch 50/50, Loss: 2.534703\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "\n",
      "Training Pipeline 2 + Model XGBClassifier\n",
      "  Fold 1/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.783812\n",
      "  Epoch 2/50, Loss: 2.754338\n",
      "  Epoch 3/50, Loss: 2.739351\n",
      "  Epoch 4/50, Loss: 2.725722\n",
      "  Epoch 5/50, Loss: 2.712831\n",
      "  Epoch 6/50, Loss: 2.700917\n",
      "  Epoch 7/50, Loss: 2.690186\n",
      "  Epoch 8/50, Loss: 2.679615\n",
      "  Epoch 9/50, Loss: 2.669700\n",
      "  Epoch 10/50, Loss: 2.660024\n",
      "  Epoch 11/50, Loss: 2.651222\n",
      "  Epoch 12/50, Loss: 2.644004\n",
      "  Epoch 13/50, Loss: 2.636311\n",
      "  Epoch 14/50, Loss: 2.629707\n",
      "  Epoch 15/50, Loss: 2.623058\n",
      "  Epoch 16/50, Loss: 2.617601\n",
      "  Epoch 17/50, Loss: 2.611911\n",
      "  Epoch 18/50, Loss: 2.607169\n",
      "  Epoch 19/50, Loss: 2.602721\n",
      "  Epoch 20/50, Loss: 2.599653\n",
      "  Epoch 21/50, Loss: 2.593712\n",
      "  Epoch 22/50, Loss: 2.591905\n",
      "  Epoch 23/50, Loss: 2.587622\n",
      "  Epoch 24/50, Loss: 2.584571\n",
      "  Epoch 25/50, Loss: 2.581610\n",
      "  Epoch 26/50, Loss: 2.578861\n",
      "  Epoch 27/50, Loss: 2.575449\n",
      "  Epoch 28/50, Loss: 2.573669\n",
      "  Epoch 29/50, Loss: 2.571155\n",
      "  Epoch 30/50, Loss: 2.567614\n",
      "  Epoch 31/50, Loss: 2.566021\n",
      "  Epoch 32/50, Loss: 2.563422\n",
      "  Epoch 33/50, Loss: 2.561333\n",
      "  Epoch 34/50, Loss: 2.559553\n",
      "  Epoch 35/50, Loss: 2.559001\n",
      "  Epoch 36/50, Loss: 2.555544\n",
      "  Epoch 37/50, Loss: 2.553366\n",
      "  Epoch 38/50, Loss: 2.552634\n",
      "  Epoch 39/50, Loss: 2.549904\n",
      "  Epoch 40/50, Loss: 2.548555\n",
      "  Epoch 41/50, Loss: 2.547761\n",
      "  Epoch 42/50, Loss: 2.546905\n",
      "  Epoch 43/50, Loss: 2.545952\n",
      "  Epoch 44/50, Loss: 2.543256\n",
      "  Epoch 45/50, Loss: 2.542643\n",
      "  Epoch 46/50, Loss: 2.540054\n",
      "  Epoch 47/50, Loss: 2.538246\n",
      "  Epoch 48/50, Loss: 2.537461\n",
      "  Epoch 49/50, Loss: 2.537156\n",
      "  Epoch 50/50, Loss: 2.535711\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 2/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.785009\n",
      "  Epoch 2/50, Loss: 2.753158\n",
      "  Epoch 3/50, Loss: 2.738837\n",
      "  Epoch 4/50, Loss: 2.725610\n",
      "  Epoch 5/50, Loss: 2.712146\n",
      "  Epoch 6/50, Loss: 2.700838\n",
      "  Epoch 7/50, Loss: 2.688954\n",
      "  Epoch 8/50, Loss: 2.678653\n",
      "  Epoch 9/50, Loss: 2.668694\n",
      "  Epoch 10/50, Loss: 2.660242\n",
      "  Epoch 11/50, Loss: 2.652679\n",
      "  Epoch 12/50, Loss: 2.644616\n",
      "  Epoch 13/50, Loss: 2.637071\n",
      "  Epoch 14/50, Loss: 2.632235\n",
      "  Epoch 15/50, Loss: 2.625934\n",
      "  Epoch 16/50, Loss: 2.620614\n",
      "  Epoch 17/50, Loss: 2.615616\n",
      "  Epoch 18/50, Loss: 2.611099\n",
      "  Epoch 19/50, Loss: 2.605669\n",
      "  Epoch 20/50, Loss: 2.601961\n",
      "  Epoch 21/50, Loss: 2.598574\n",
      "  Epoch 22/50, Loss: 2.594981\n",
      "  Epoch 23/50, Loss: 2.590837\n",
      "  Epoch 24/50, Loss: 2.588124\n",
      "  Epoch 25/50, Loss: 2.585160\n",
      "  Epoch 26/50, Loss: 2.582197\n",
      "  Epoch 27/50, Loss: 2.579047\n",
      "  Epoch 28/50, Loss: 2.576317\n",
      "  Epoch 29/50, Loss: 2.574841\n",
      "  Epoch 30/50, Loss: 2.571843\n",
      "  Epoch 31/50, Loss: 2.569167\n",
      "  Epoch 32/50, Loss: 2.567038\n",
      "  Epoch 33/50, Loss: 2.565075\n",
      "  Epoch 34/50, Loss: 2.562913\n",
      "  Epoch 35/50, Loss: 2.561313\n",
      "  Epoch 36/50, Loss: 2.558925\n",
      "  Epoch 37/50, Loss: 2.557627\n",
      "  Epoch 38/50, Loss: 2.554753\n",
      "  Epoch 39/50, Loss: 2.554422\n",
      "  Epoch 40/50, Loss: 2.551171\n",
      "  Epoch 41/50, Loss: 2.551162\n",
      "  Epoch 42/50, Loss: 2.549033\n",
      "  Epoch 43/50, Loss: 2.547287\n",
      "  Epoch 44/50, Loss: 2.546771\n",
      "  Epoch 45/50, Loss: 2.544981\n",
      "  Epoch 46/50, Loss: 2.542430\n",
      "  Epoch 47/50, Loss: 2.541577\n",
      "  Epoch 48/50, Loss: 2.540766\n",
      "  Epoch 49/50, Loss: 2.539338\n",
      "  Epoch 50/50, Loss: 2.538220\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 3/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.781145\n",
      "  Epoch 2/50, Loss: 2.751268\n",
      "  Epoch 3/50, Loss: 2.735836\n",
      "  Epoch 4/50, Loss: 2.720971\n",
      "  Epoch 5/50, Loss: 2.707340\n",
      "  Epoch 6/50, Loss: 2.695097\n",
      "  Epoch 7/50, Loss: 2.683162\n",
      "  Epoch 8/50, Loss: 2.672370\n",
      "  Epoch 9/50, Loss: 2.662332\n",
      "  Epoch 10/50, Loss: 2.653266\n",
      "  Epoch 11/50, Loss: 2.644985\n",
      "  Epoch 12/50, Loss: 2.637470\n",
      "  Epoch 13/50, Loss: 2.630692\n",
      "  Epoch 14/50, Loss: 2.624185\n",
      "  Epoch 15/50, Loss: 2.618555\n",
      "  Epoch 16/50, Loss: 2.612782\n",
      "  Epoch 17/50, Loss: 2.608276\n",
      "  Epoch 18/50, Loss: 2.603724\n",
      "  Epoch 19/50, Loss: 2.596638\n",
      "  Epoch 20/50, Loss: 2.594256\n",
      "  Epoch 21/50, Loss: 2.589796\n",
      "  Epoch 22/50, Loss: 2.586596\n",
      "  Epoch 23/50, Loss: 2.583516\n",
      "  Epoch 24/50, Loss: 2.579947\n",
      "  Epoch 25/50, Loss: 2.576843\n",
      "  Epoch 26/50, Loss: 2.575702\n",
      "  Epoch 27/50, Loss: 2.571443\n",
      "  Epoch 28/50, Loss: 2.568537\n",
      "  Epoch 29/50, Loss: 2.567138\n",
      "  Epoch 30/50, Loss: 2.564581\n",
      "  Epoch 31/50, Loss: 2.561596\n",
      "  Epoch 32/50, Loss: 2.559535\n",
      "  Epoch 33/50, Loss: 2.557395\n",
      "  Epoch 34/50, Loss: 2.556361\n",
      "  Epoch 35/50, Loss: 2.553056\n",
      "  Epoch 36/50, Loss: 2.551551\n",
      "  Epoch 37/50, Loss: 2.549735\n",
      "  Epoch 38/50, Loss: 2.547797\n",
      "  Epoch 39/50, Loss: 2.546681\n",
      "  Epoch 40/50, Loss: 2.545820\n",
      "  Epoch 41/50, Loss: 2.543278\n",
      "  Epoch 42/50, Loss: 2.542103\n",
      "  Epoch 43/50, Loss: 2.540289\n",
      "  Epoch 44/50, Loss: 2.539608\n",
      "  Epoch 45/50, Loss: 2.537849\n",
      "  Epoch 46/50, Loss: 2.535088\n",
      "  Epoch 47/50, Loss: 2.534922\n",
      "  Epoch 48/50, Loss: 2.534386\n",
      "  Epoch 49/50, Loss: 2.533473\n",
      "  Epoch 50/50, Loss: 2.532480\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 4/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.780348\n",
      "  Epoch 2/50, Loss: 2.750330\n",
      "  Epoch 3/50, Loss: 2.734869\n",
      "  Epoch 4/50, Loss: 2.720709\n",
      "  Epoch 5/50, Loss: 2.707793\n",
      "  Epoch 6/50, Loss: 2.694621\n",
      "  Epoch 7/50, Loss: 2.682975\n",
      "  Epoch 8/50, Loss: 2.672849\n",
      "  Epoch 9/50, Loss: 2.662792\n",
      "  Epoch 10/50, Loss: 2.654099\n",
      "  Epoch 11/50, Loss: 2.644826\n",
      "  Epoch 12/50, Loss: 2.637952\n",
      "  Epoch 13/50, Loss: 2.630921\n",
      "  Epoch 14/50, Loss: 2.624104\n",
      "  Epoch 15/50, Loss: 2.617828\n",
      "  Epoch 16/50, Loss: 2.612315\n",
      "  Epoch 17/50, Loss: 2.607600\n",
      "  Epoch 18/50, Loss: 2.601784\n",
      "  Epoch 19/50, Loss: 2.597989\n",
      "  Epoch 20/50, Loss: 2.593542\n",
      "  Epoch 21/50, Loss: 2.588958\n",
      "  Epoch 22/50, Loss: 2.586896\n",
      "  Epoch 23/50, Loss: 2.581743\n",
      "  Epoch 24/50, Loss: 2.580595\n",
      "  Epoch 25/50, Loss: 2.576794\n",
      "  Epoch 26/50, Loss: 2.572862\n",
      "  Epoch 27/50, Loss: 2.571614\n",
      "  Epoch 28/50, Loss: 2.567565\n",
      "  Epoch 29/50, Loss: 2.566786\n",
      "  Epoch 30/50, Loss: 2.562737\n",
      "  Epoch 31/50, Loss: 2.561781\n",
      "  Epoch 32/50, Loss: 2.558981\n",
      "  Epoch 33/50, Loss: 2.556257\n",
      "  Epoch 34/50, Loss: 2.554657\n",
      "  Epoch 35/50, Loss: 2.552829\n",
      "  Epoch 36/50, Loss: 2.551266\n",
      "  Epoch 37/50, Loss: 2.549645\n",
      "  Epoch 38/50, Loss: 2.548543\n",
      "  Epoch 39/50, Loss: 2.546019\n",
      "  Epoch 40/50, Loss: 2.545587\n",
      "  Epoch 41/50, Loss: 2.542946\n",
      "  Epoch 42/50, Loss: 2.541276\n",
      "  Epoch 43/50, Loss: 2.539896\n",
      "  Epoch 44/50, Loss: 2.538837\n",
      "  Epoch 45/50, Loss: 2.538012\n",
      "  Epoch 46/50, Loss: 2.535431\n",
      "  Epoch 47/50, Loss: 2.535390\n",
      "  Epoch 48/50, Loss: 2.534735\n",
      "  Epoch 49/50, Loss: 2.531822\n",
      "  Epoch 50/50, Loss: 2.531919\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "  Fold 5/5...\n",
      "CNN Feature Generator: Starting training on cuda for 50 epochs...\n",
      "  Epoch 1/50, Loss: 2.785902\n",
      "  Epoch 2/50, Loss: 2.753570\n",
      "  Epoch 3/50, Loss: 2.738375\n",
      "  Epoch 4/50, Loss: 2.723899\n",
      "  Epoch 5/50, Loss: 2.709782\n",
      "  Epoch 6/50, Loss: 2.697073\n",
      "  Epoch 7/50, Loss: 2.685505\n",
      "  Epoch 8/50, Loss: 2.675393\n",
      "  Epoch 9/50, Loss: 2.665062\n",
      "  Epoch 10/50, Loss: 2.655731\n",
      "  Epoch 11/50, Loss: 2.648091\n",
      "  Epoch 12/50, Loss: 2.640144\n",
      "  Epoch 13/50, Loss: 2.632771\n",
      "  Epoch 14/50, Loss: 2.627013\n",
      "  Epoch 15/50, Loss: 2.621049\n",
      "  Epoch 16/50, Loss: 2.614401\n",
      "  Epoch 17/50, Loss: 2.610492\n",
      "  Epoch 18/50, Loss: 2.605516\n",
      "  Epoch 19/50, Loss: 2.601094\n",
      "  Epoch 20/50, Loss: 2.596694\n",
      "  Epoch 21/50, Loss: 2.593245\n",
      "  Epoch 22/50, Loss: 2.589072\n",
      "  Epoch 23/50, Loss: 2.585356\n",
      "  Epoch 24/50, Loss: 2.581500\n",
      "  Epoch 25/50, Loss: 2.579017\n",
      "  Epoch 26/50, Loss: 2.576807\n",
      "  Epoch 27/50, Loss: 2.574732\n",
      "  Epoch 28/50, Loss: 2.571117\n",
      "  Epoch 29/50, Loss: 2.568752\n",
      "  Epoch 30/50, Loss: 2.566912\n",
      "  Epoch 31/50, Loss: 2.565064\n",
      "  Epoch 32/50, Loss: 2.562962\n",
      "  Epoch 33/50, Loss: 2.561360\n",
      "  Epoch 34/50, Loss: 2.559121\n",
      "  Epoch 35/50, Loss: 2.556823\n",
      "  Epoch 36/50, Loss: 2.557010\n",
      "  Epoch 37/50, Loss: 2.553665\n",
      "  Epoch 38/50, Loss: 2.551738\n",
      "  Epoch 39/50, Loss: 2.549924\n",
      "  Epoch 40/50, Loss: 2.549085\n",
      "  Epoch 41/50, Loss: 2.546933\n",
      "  Epoch 42/50, Loss: 2.546275\n",
      "  Epoch 43/50, Loss: 2.543996\n",
      "  Epoch 44/50, Loss: 2.543917\n",
      "  Epoch 45/50, Loss: 2.542755\n",
      "  Epoch 46/50, Loss: 2.540792\n",
      "  Epoch 47/50, Loss: 2.540976\n",
      "  Epoch 48/50, Loss: 2.538560\n",
      "  Epoch 49/50, Loss: 2.537376\n",
      "  Epoch 50/50, Loss: 2.536588\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namwonjin\\Documents\\Kaggle\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HybridFullStackingClassifier(meta_model=LogisticRegression(),\n",
       "                             model_defs=[(&lt;class &#x27;catboost.core.CatBoostClassifier&#x27;&gt;,\n",
       "                                          {&#x27;bootstrap_type&#x27;: &#x27;Poisson&#x27;,\n",
       "                                           &#x27;depth&#x27;: 8,\n",
       "                                           &#x27;early_stopping_rounds&#x27;: 200,\n",
       "                                           &#x27;eval_metric&#x27;: &#x27;MultiClass&#x27;,\n",
       "                                           &#x27;grow_policy&#x27;: &#x27;Depthwise&#x27;,\n",
       "                                           &#x27;iterations&#x27;: 2000, &#x27;l2_leaf_reg&#x27;: 3,\n",
       "                                           &#x27;learning_rate&#x27;: 0.05,\n",
       "                                           &#x27;loss_function&#x27;: &#x27;MultiClass&#x27;,\n",
       "                                           &#x27;random_seed&#x27;: 42, &#x27;subsample&#x27;: 0....\n",
       "                                                                                 &#x27;tof_1_v10&#x27;,\n",
       "                                                                                 &#x27;tof_1_v11&#x27;,\n",
       "                                                                                 &#x27;tof_1_v12&#x27;,\n",
       "                                                                                 &#x27;tof_1_v13&#x27;,\n",
       "                                                                                 &#x27;tof_1_v14&#x27;,\n",
       "                                                                                 &#x27;tof_1_v15&#x27;,\n",
       "                                                                                 &#x27;tof_1_v16&#x27;,\n",
       "                                                                                 &#x27;tof_1_v17&#x27;,\n",
       "                                                                                 &#x27;tof_1_v18&#x27;,\n",
       "                                                                                 &#x27;tof_1_v19&#x27;,\n",
       "                                                                                 &#x27;tof_1_v20&#x27;,\n",
       "                                                                                 &#x27;tof_1_v21&#x27;,\n",
       "                                                                                 &#x27;tof_1_v22&#x27;,\n",
       "                                                                                 &#x27;tof_1_v23&#x27;,\n",
       "                                                                                 &#x27;tof_1_v24&#x27;,\n",
       "                                                                                 &#x27;tof_1_v25&#x27;,\n",
       "                                                                                 &#x27;tof_1_v26&#x27;,\n",
       "                                                                                 &#x27;tof_1_v27&#x27;,\n",
       "                                                                                 &#x27;tof_1_v28&#x27;,\n",
       "                                                                                 &#x27;tof_1_v29&#x27;, ...]))]),\n",
       "                                        Pipeline(steps=[(&#x27;cnn_features&#x27;,\n",
       "                                                         CNNFeatureGenerator(batch_size=128,\n",
       "                                                                             epochs=50,\n",
       "                                                                             feature_dim=64,\n",
       "                                                                             num_classes=18))])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;HybridFullStackingClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>HybridFullStackingClassifier(meta_model=LogisticRegression(),\n",
       "                             model_defs=[(&lt;class &#x27;catboost.core.CatBoostClassifier&#x27;&gt;,\n",
       "                                          {&#x27;bootstrap_type&#x27;: &#x27;Poisson&#x27;,\n",
       "                                           &#x27;depth&#x27;: 8,\n",
       "                                           &#x27;early_stopping_rounds&#x27;: 200,\n",
       "                                           &#x27;eval_metric&#x27;: &#x27;MultiClass&#x27;,\n",
       "                                           &#x27;grow_policy&#x27;: &#x27;Depthwise&#x27;,\n",
       "                                           &#x27;iterations&#x27;: 2000, &#x27;l2_leaf_reg&#x27;: 3,\n",
       "                                           &#x27;learning_rate&#x27;: 0.05,\n",
       "                                           &#x27;loss_function&#x27;: &#x27;MultiClass&#x27;,\n",
       "                                           &#x27;random_seed&#x27;: 42, &#x27;subsample&#x27;: 0....\n",
       "                                                                                 &#x27;tof_1_v10&#x27;,\n",
       "                                                                                 &#x27;tof_1_v11&#x27;,\n",
       "                                                                                 &#x27;tof_1_v12&#x27;,\n",
       "                                                                                 &#x27;tof_1_v13&#x27;,\n",
       "                                                                                 &#x27;tof_1_v14&#x27;,\n",
       "                                                                                 &#x27;tof_1_v15&#x27;,\n",
       "                                                                                 &#x27;tof_1_v16&#x27;,\n",
       "                                                                                 &#x27;tof_1_v17&#x27;,\n",
       "                                                                                 &#x27;tof_1_v18&#x27;,\n",
       "                                                                                 &#x27;tof_1_v19&#x27;,\n",
       "                                                                                 &#x27;tof_1_v20&#x27;,\n",
       "                                                                                 &#x27;tof_1_v21&#x27;,\n",
       "                                                                                 &#x27;tof_1_v22&#x27;,\n",
       "                                                                                 &#x27;tof_1_v23&#x27;,\n",
       "                                                                                 &#x27;tof_1_v24&#x27;,\n",
       "                                                                                 &#x27;tof_1_v25&#x27;,\n",
       "                                                                                 &#x27;tof_1_v26&#x27;,\n",
       "                                                                                 &#x27;tof_1_v27&#x27;,\n",
       "                                                                                 &#x27;tof_1_v28&#x27;,\n",
       "                                                                                 &#x27;tof_1_v29&#x27;, ...]))]),\n",
       "                                        Pipeline(steps=[(&#x27;cnn_features&#x27;,\n",
       "                                                         CNNFeatureGenerator(batch_size=128,\n",
       "                                                                             epochs=50,\n",
       "                                                                             feature_dim=64,\n",
       "                                                                             num_classes=18))])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">meta_model: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HybridFullStackingClassifier(meta_model=LogisticRegression(),\n",
       "                             model_defs=[(<class 'catboost.core.CatBoostClassifier'>,\n",
       "                                          {'bootstrap_type': 'Poisson',\n",
       "                                           'depth': 8,\n",
       "                                           'early_stopping_rounds': 200,\n",
       "                                           'eval_metric': 'MultiClass',\n",
       "                                           'grow_policy': 'Depthwise',\n",
       "                                           'iterations': 2000, 'l2_leaf_reg': 3,\n",
       "                                           'learning_rate': 0.05,\n",
       "                                           'loss_function': 'MultiClass',\n",
       "                                           'random_seed': 42, 'subsample': 0....\n",
       "                                                                                 'tof_1_v10',\n",
       "                                                                                 'tof_1_v11',\n",
       "                                                                                 'tof_1_v12',\n",
       "                                                                                 'tof_1_v13',\n",
       "                                                                                 'tof_1_v14',\n",
       "                                                                                 'tof_1_v15',\n",
       "                                                                                 'tof_1_v16',\n",
       "                                                                                 'tof_1_v17',\n",
       "                                                                                 'tof_1_v18',\n",
       "                                                                                 'tof_1_v19',\n",
       "                                                                                 'tof_1_v20',\n",
       "                                                                                 'tof_1_v21',\n",
       "                                                                                 'tof_1_v22',\n",
       "                                                                                 'tof_1_v23',\n",
       "                                                                                 'tof_1_v24',\n",
       "                                                                                 'tof_1_v25',\n",
       "                                                                                 'tof_1_v26',\n",
       "                                                                                 'tof_1_v27',\n",
       "                                                                                 'tof_1_v28',\n",
       "                                                                                 'tof_1_v29', ...]))]),\n",
       "                                        Pipeline(steps=[('cnn_features',\n",
       "                                                         CNNFeatureGenerator(batch_size=128,\n",
       "                                                                             epochs=50,\n",
       "                                                                             feature_dim=64,\n",
       "                                                                             num_classes=18))])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = HybridFullStackingClassifier(\n",
    "    pipelines=pipelines,\n",
    "    model_defs=model_defs,\n",
    "    n_splits = CFG.folds, \n",
    "    random_state = CFG.seed,\n",
    "    meta_model=LogisticRegression(),\n",
    "    n_bins=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Polars Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏùÑ ÏûÖÎ†•ÏúºÎ°ú ÌïôÏäµ ÏãúÏûë\n",
    "ensemble.fit(train_X_full, train_y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f335e581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n",
      "CNN Feature Generator: Extracting features...\n"
     ]
    }
   ],
   "source": [
    "test_X = test.drop(['row_id'])\n",
    "predictions = ensemble.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09e7a358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'submission.csv' ÌååÏùº ÏÉùÏÑ±Ïù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§!\n",
      "shape: (5, 2)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ row_id            ‚îÜ gesture       ‚îÇ\n",
      "‚îÇ ---               ‚îÜ ---           ‚îÇ\n",
      "‚îÇ str               ‚îÜ str           ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ SEQ_000001_000000 ‚îÜ Text on phone ‚îÇ\n",
      "‚îÇ SEQ_000001_000001 ‚îÜ Text on phone ‚îÇ\n",
      "‚îÇ SEQ_000001_000002 ‚îÜ Text on phone ‚îÇ\n",
      "‚îÇ SEQ_000001_000003 ‚îÜ Text on phone ‚îÇ\n",
      "‚îÇ SEQ_000001_000004 ‚îÜ Text on phone ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "submission_df = pl.DataFrame({\n",
    "    'row_id': test['row_id'],\n",
    "    'gesture': predictions\n",
    "})\n",
    "\n",
    "# 4. CSV ÌååÏùºÎ°ú Ï†ÄÏû•\n",
    "submission_df.write_csv('submission.csv')\n",
    "\n",
    "print(\"\\n'submission.csv' ÌååÏùº ÏÉùÏÑ±Ïù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§!\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
